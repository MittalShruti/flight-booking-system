{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATIS Flight Reservations Dataset\n",
    "\n",
    "Dataset download link: http://lisaweb.iro.umontreal.ca/transfert/lisa/users/mesnilgr/atis/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, pprint, os\n",
    "import gzip, os, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the first part of the dataset\n",
    "# each part (.gz file) contains train, validation and test sets, plus a dict\n",
    "\n",
    "filename = 'atis.fold0.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "try:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')\n",
    "except:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f)\n",
    "finally:\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3983)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3983)\n",
      "(3, 995)\n",
      "(3, 893)\n"
     ]
    }
   ],
   "source": [
    "# structure of the component data files\n",
    "print(np.shape(train_set))\n",
    "print(np.shape(valid_set))\n",
    "print(np.shape(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<class 'list'>\n",
      "3983\n"
     ]
    }
   ],
   "source": [
    "# each set is a 3-tuple, each element of the tuple being a list \n",
    "print(len(train_set))\n",
    "print(type(train_set[0]))\n",
    "print(len(train_set[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list has 3983 arrays, each array being a sentence. The words are encoded by numbers (and have to be decoded using the dict provided).\n",
    "\n",
    "Let's store the three lists into separate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the three elements of the tuple in three objects\n",
    "train_x, _, train_label = train_set\n",
    "val_x, _, val_label = valid_set\n",
    "test_x, _, test_label = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list represents the actual words (encoded), and the third list contains their labels (again, encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([554, 194, 268,  64,  62,  16,   8, 234, 481,  20,  40,  58, 234,\n",
       "       415, 205])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each list in the tuple is a numpy array (a sentence)\n",
    "# printing first list in the tuple's first element\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 126, 126,  48, 126,  36,  35, 126, 126,  33, 126, 126, 126,\n",
       "        78, 123])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels are stored in the third list train_label\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['labels2idx', 'tables2idx', 'words2idx'])\n"
     ]
    }
   ],
   "source": [
    "# dicts \n",
    "print(type(dicts))\n",
    "print(dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# each key:value pair is itself a dict\n",
    "print(type(dicts['labels2idx']))\n",
    "print(type(dicts['tables2idx']))\n",
    "print(type(dicts['words2idx']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing labels and words in separate variables\n",
    "words = dicts['words2idx']\n",
    "labels = dicts['labels2idx']\n",
    "tables = dicts['tables2idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all', 'coach', 'cincinnati', 'people', 'month', 'four', 'code', 'go', 'show', 'thursday', 'to', 'restriction', 'dinnertime', 'under', 'sorry', 'include', 'midwest', 'worth', 'southwest', 'me', 'returning', 'far', 'vegas', 'airfare', 'ticket', 'difference', 'arrange', 'tickets', 'louis', 'cheapest', 'list', 'wednesday', 'leave', 'heading', 'ten', 'direct', 'turboprop', 'rate', 'cost', 'quebec', 'layover', 'air', 'what', 'stands', 'chicago', 'schedule', 'transcontinental', 'goes', 'new', 'transportation', 'here', 'hours', 'let', 'twentieth', 'along', 'thrift', 'passengers', 'great', 'thirty', 'canadian', 'leaves', 'alaska', 'leaving', 'amount', 'weekday', 'makes', 'midway', 'montreal', 'via', 'depart', 'county', 'names', 'stand', 'total', 'seventeenth', 'use', 'twa', 'from', 'would', 'abbreviations', 'destination', 'only', 'next', 'live', 'shortest', 'limousine', 'tell', 'today', 'more', 'DIGIT', 'm80', 'downtown', 'train', 'tampa', 'fly', 'f', 'this', 'car', 'anywhere', 'can', 'following', 'making', 'arrive', 'my', 'could', 'give', 'december', 'numbers', 'want', 'DIGITDIGITDIGITDIGITDIGITDIGIT', 'airplane', 'times', 'information', 'tacoma', 'provide', 'travel', 'six', 'dinner', 'located', 'sunday', 'fourth', 'types', 'beach', 'nonstop', 'economy', 'fare', 'okay', 'y', 'may', 'earlier', 'plane', 'ff', 'coming', 'eighth', 'fn', 'las', 'a', 'boeing', 'third', 'departure', 'q', 'so', 'rentals', 'houston', 'serving', 'help', 'september', 'over', 'midnight', 'soon', 'logan', 'through', 'milwaukee', 'still', 'before', 'thirtieth', 'thank', 'fit', 'how', 'trying', 'denver', 'actually', 'late', 'offers', 'listing', 'texas', 'DIGITDIGITDIGITDIGIT', 'then', 'evening', 'return', 'yn', 'lunch', 'wednesdays', 'they', 'arriving', 'now', 'rental', 'day', 'landings', 'february', 'airports', 'name', 'sundays', 'january', 'detroit', 'each', 'meal', 'dulles', 'petersburg', 'thirteenth', 'ea', 'used', 'arrives', 'connect', 'requesting', 'tenth', 'saturday', 'out', 'canada', 'looking', 'arizona', 'cars', 'friday', 'seventh', 'california', 'york', 'bwi', 'ord', 'earliest', 'repeat', 'dc10', 'atl', 'florida', 'days', 'round', 'american', 'afternoon', 'st.', 'first', 'there', 'number', 'one', 'eleventh', 'approximately', 'another', 'tomorrow', '<UNK>', 'city', 'service', 'twenty', 'dfw', 'weekdays', 'least', 'their', 'rates', 'DIGITDIGITDIGIT', 'time', 'too', 'sixteenth', 'that', 'pittsburgh', 'serve', 'july', 'than', 'toronto', 'distance', 'kind', 'b', 'second', 'pennsylvania', 'classes', 'other', 'traveling', 'and', 'charlotte', 'san', 'stopovers', 'boston', 'takeoff', 'say', 'buy', 'rent', 'have', 'need', 'breakfast', 'philly', 'any', 'sa', 'dallas', 'also', 'without', 'take', 'which', 'sure', 'price', 'who', 'serviced', 'most', 'eight', 'landing', 'services', 'america', 'class', 'later', 'm', 'nineteenth', 'salt', 'departing', 'cheap', 'tuesdays', 'find', 'fifth', 'ground', 'snack', 'with', 'explain', 'minnesota', 'should', 'flights', 'going', 'qx', 'carolina', 'do', 'dl', 'get', 'michigan', 'express', 'stop', 'dc', 'international', 'during', 'westchester', 'qw', 'stapleton', 'h', 'morning', 'wish', 'ohio', 'where', 'qo', 'arrival', 'eighteenth', 'up', 'connections', 'see', 'are', 'close', 'yes', 'capacity', 'please', 'smallest', 'various', 'between', 'f28', 'available', 'we', 'august', 's', 'nashville', 'aircraft', 'fifteenth', 'cities', 'jfk', 'both', 'c', 'last', 'many', 'taking', 'la', 'trips', 'april', 'connection', 'baltimore', 'flies', 'co', 'tuesday', 'nonstops', 'tennessee', 'stopover', 'cp', 'november', 'expensive', 'west', 'airlines', 'nationair', 'much', 'define', 'mco', 'flight', 'eastern', 'airplanes', 'lives', 'prices', 'atlanta', 'an', 'those', 'sfo', 'georgia', 'look', 'these', 'originate', 'choices', 'will', 'near', 'itinerary', 'stopping', 'mitchell', 'fourteenth', 'thursdays', 'is', 'it', 'arrangements', 'in', 'seattle', 'if', 'different', 'make', 'airport', 'same', 'northwest', 'ewr', 'twelfth', 'week', 'indianapolis', 'diego', 'takeoffs', 'uses', 'two', 'database', 'i', 'well', 'options', 'costs', 'jersey', 'very', 'the', 'latest', 'taxi', 'just', 'less', 'ninth', 'abbreviation', 'seats', 'love', 'paul', 'jose', 'sixteen', 'lake', 'book', 'ap80', 'fares', 'has', 'march', 'around', 'utah', 'possible', 'early', 'know', 'schedules', 'using', 'like', 'd', 'miami', 'orlando', 'arrivals', 'either', 'night', 'served', 'tower', 'limo', 'seating', 'right', 'saturdays', 'lastest', 'some', 'back', \"'t\", 'serves', 'cleveland', \"'s\", 'transport', 'provided', 'oakland', 'phoenix', 'for', 'noon', 'stops', 'newark', 'does', 'connecting', 'booking', 'be', 'columbus', 'business', 'reaching', 'sixth', 'departures', 'ap57', 'by', 'after', 'on', 'about', 'noontime', 'DIGITDIGIT', 'of', 'dollars', 'burbank', 'angeles', 'carries', 'airline', 'mean', 'or', 'plan', 'colorado', 'united', 'into', 'within', 'washington', 'bound', 'three', 'your', 'guardia', 'ontario', 'area', 'flying', 'philadelphia', 'long', 'continental', 'los', '72s', 'way', 'lowest', 'mornings', 'north', 'offer', 'hp', 'restrictions', 'but', 'hi', 'delta', 'highest', 'memphis', 'fort', 'october', 'type', 'maximum', 'us', \"'re\", 'planes', 'pm', 'ua', 'display', 'originating', 'ac', 'reservations', 'describe', 'am', 'minneapolis', 'general', 'ap', 'as', 'sometime', 'at', 'trip', 'again', 'codes', \"'ll\", 'no', 'when', 'field', 'interested', 'you', 'nw', 'francisco', 'kinds', 'monday', \"o'clock\", 'kansas', 'june', 'lufthansa', 'meaning', \"'d\", 'reservation', \"'m\", 'friends', 'meals', 'land', 'daily', 'departs', 'missouri', 'starting', 'hello'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each key of words_dict is a word, each value its index\n",
    "words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'flights',\n",
       " 'leave',\n",
       " 'atlanta',\n",
       " 'at',\n",
       " 'about',\n",
       " 'DIGIT',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'and',\n",
       " 'arrive',\n",
       " 'in',\n",
       " 'san',\n",
       " 'francisco']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we can map the numeric values v in a sentence with the k,v in the dict\n",
    "# train_x contains the list of training sentences\n",
    "# this is the first sentence\n",
    "[k for val in train_x[0] for k,v in words.items() if v==val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco',\n",
       " 'what is the abbreviation for canadian airlines international',\n",
       " \"i 'd like to know the earliest flight from boston to atlanta\",\n",
       " 'show me the us air flights from atlanta to boston',\n",
       " 'show me the cheapest round trips from dallas to baltimore',\n",
       " \"i 'd like to see all flights from denver to philadelphia\",\n",
       " 'explain fare code qx',\n",
       " \"i 'd like a united airlines flight on wednesday from san francisco to boston\",\n",
       " 'what is the price of american airlines flight DIGITDIGIT from new york to los angeles',\n",
       " 'what does the meal code s stand for',\n",
       " 'what are all flights to denver from philadelphia on sunday',\n",
       " 'what times does the late afternoon flight leave from washington for denver',\n",
       " 'what flights are available monday from san francisco to pittsburgh',\n",
       " 'what airlines have business class',\n",
       " 'flights from atlanta to washington dc',\n",
       " 'from new york to toronto on thursday morning',\n",
       " 'show me all the direct flights from atlanta to baltimore',\n",
       " 'list the flights from new york to miami on a tuesday which are nonstop and cost less than DIGITDIGITDIGIT dollars',\n",
       " 'show me the first flight that arrives in toronto from cincinnati',\n",
       " 'what planes are used by twa',\n",
       " 'please give me the prices for all flights from philadelphia to denver airport next sunday',\n",
       " 'show me all flights from pittsburgh to oakland that arrive after DIGITDIGIT am',\n",
       " 'what is the least expensive flight today from atlanta to san francisco',\n",
       " 'i want a flight from philadelphia to dallas with a stop in atlanta',\n",
       " 'show me the flights from baltimore to philadelphia',\n",
       " 'what airlines fly from st. petersburg to milwaukee and from milwaukee to tacoma',\n",
       " 'please give me the flights from san francisco to washington dc',\n",
       " 'i need a flight delta airlines kansas city to salt lake',\n",
       " 'show me flights going from boston to denver arriving on wednesday morning',\n",
       " 'show me flights leaving from denver colorado to pittsburgh pennsylvania on wednesdays after DIGIT pm']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the first few sentences\n",
    "sents = []\n",
    "for i in range(30):\n",
    "    sents.append(' '.join([k for val in train_x[i] for k,v in words.items() if v==val]))\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['B-time_relative', 'B-stoploc.state_code', 'B-depart_date.today_relative', 'B-arrive_date.date_relative', 'B-depart_date.date_relative', 'I-restriction_code', 'B-return_date.month_name', 'I-time', 'B-depart_date.day_name', 'I-arrive_time.end_time', 'B-fromloc.airport_code', 'B-cost_relative', 'B-connect', 'B-return_time.period_mod', 'B-arrive_time.period_mod', 'B-flight_number', 'B-depart_time.time_relative', 'I-toloc.city_name', 'B-arrive_time.period_of_day', 'B-depart_time.period_of_day', 'I-return_date.date_relative', 'I-depart_time.start_time', 'B-fare_amount', 'I-depart_time.time_relative', 'B-city_name', 'B-depart_date.day_number', 'I-meal_description', 'I-depart_date.today_relative', 'I-airport_name', 'I-arrive_date.day_number', 'B-toloc.state_code', 'B-arrive_date.month_name', 'B-stoploc.airport_code', 'I-depart_time.time', 'B-airport_code', 'B-arrive_time.start_time', 'B-period_of_day', 'B-arrive_time.time', 'I-flight_stop', 'B-toloc.state_name', 'B-booking_class', 'I-meal_code', 'B-arrive_time.end_time', 'B-meal', 'B-arrive_time.time_relative', 'B-return_date.day_number', 'I-city_name', 'B-day_name', 'B-or', 'I-flight_mod', 'I-arrive_time.time', 'B-economy', 'B-fromloc.airport_name', 'B-return_date.day_name', 'O', 'B-class_type', 'B-meal_code', 'B-depart_time.time', 'B-return_date.today_relative', 'B-round_trip', 'B-restriction_code', 'B-fare_basis_code', 'I-stoploc.city_name', 'I-fare_basis_code', 'B-flight', 'I-fromloc.airport_name', 'B-compartment', 'B-airline_code', 'B-fromloc.state_name', 'B-flight_stop', 'B-day_number', 'B-flight_mod', 'I-arrive_time.period_of_day', 'B-depart_time.start_time', 'B-today_relative', 'I-arrive_time.time_relative', 'B-arrive_date.day_number', 'I-flight_time', 'B-arrive_date.day_name', 'I-fromloc.state_name', 'B-mod', 'B-depart_date.month_name', 'B-flight_days', 'I-cost_relative', 'B-stoploc.airport_name', 'I-today_relative', 'B-fromloc.city_name', 'B-transport_type', 'B-return_time.period_of_day', 'B-time', 'B-toloc.country_name', 'B-return_date.date_relative', 'I-depart_date.day_number', 'I-transport_type', 'I-fromloc.city_name', 'B-depart_date.year', 'I-return_date.day_number', 'B-flight_time', 'B-toloc.city_name', 'B-depart_time.period_mod', 'I-arrive_time.start_time', 'B-state_code', 'B-airport_name', 'B-stoploc.city_name', 'I-toloc.airport_name', 'B-meal_description', 'I-class_type', 'B-toloc.airport_code', 'I-depart_time.period_of_day', 'I-toloc.state_name', 'B-days_code', 'B-toloc.airport_name', 'B-arrive_date.today_relative', 'I-round_trip', 'I-state_name', 'I-fare_amount', 'B-airline_name', 'I-flight_number', 'I-airline_name', 'B-state_name', 'I-economy', 'B-depart_time.end_time', 'B-aircraft_code', 'I-return_date.today_relative', 'B-month_name', 'B-fromloc.state_code', 'I-depart_time.end_time'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels dict contains IOB (inside-out-beginning) labelled entities\n",
    "labels.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 127 classes of labels (including the 'O' - tokens that do not fall into any entity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "# number of labels\n",
    "print(len(labels.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dicts 'words' and 'labels' are key:value pairs of index:word/label, let's reverse the dicts so that we don't have to do a reverse lookup everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting words_to_id to id_to_words\n",
    "# and labels_to_id to id_to_labels\n",
    "id_to_words = {words[k]:k for k in words}\n",
    "id_to_labels = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the words and corresponding labels simply by looking up the value of a numeric index of each word, for e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('is', 'O'), ('there', 'O'), ('a', 'O'), ('nonstop', 'B-flight_stop'), ('flight', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('san', 'B-toloc.city_name'), ('francisco', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('need', 'O'), ('information', 'O'), ('for', 'O'), ('a', 'O'), ('flight', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('atlanta', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('flights', 'O'), ('from', 'O'), ('westchester', 'B-fromloc.city_name'), ('county', 'I-fromloc.city_name'), ('to', 'O'), ('st.', 'B-toloc.city_name'), ('paul', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('a', 'O'), ('list', 'O'), ('of', 'O'), ('flights', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('atlanta', 'B-toloc.city_name'), ('leaving', 'O'), ('after', 'B-depart_time.time_relative'), ('noon', 'B-depart_time.time'), ('and', 'O'), ('arriving', 'O'), ('before', 'B-arrive_time.time_relative'), ('DIGIT', 'B-arrive_time.time'), ('pm', 'I-arrive_time.time')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('from', 'O'), ('salt', 'B-fromloc.city_name'), ('lake', 'I-fromloc.city_name'), ('city', 'I-fromloc.city_name'), ('to', 'O'), ('new', 'B-toloc.city_name'), ('york', 'I-toloc.city_name'), ('city', 'I-toloc.city_name'), ('arrive', 'O'), ('next', 'B-arrive_date.date_relative'), ('saturday', 'B-arrive_date.day_name'), ('before', 'B-arrive_time.time_relative'), ('DIGIT', 'B-arrive_time.time'), ('pm', 'I-arrive_time.time')]\n",
      "\n",
      "\n",
      "[('information', 'O'), ('on', 'O'), ('flights', 'O'), ('from', 'O'), ('atlanta', 'B-fromloc.city_name'), ('to', 'O'), ('washington', 'B-toloc.city_name'), ('dc', 'B-toloc.state_code'), ('departing', 'O'), ('on', 'O'), ('thursday', 'B-depart_date.day_name'), ('before', 'B-depart_time.time_relative'), ('DIGIT', 'B-depart_time.time'), ('am', 'I-depart_time.time')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('a', 'O'), ('flight', 'O'), ('from', 'O'), ('nashville', 'B-fromloc.city_name'), ('to', 'O'), ('st.', 'B-toloc.city_name'), ('louis', 'I-toloc.city_name'), ('that', 'O'), ('arrives', 'O'), ('in', 'O'), ('st.', 'B-toloc.city_name'), ('louis', 'I-toloc.city_name'), ('around', 'B-arrive_time.time_relative'), ('DIGIT', 'B-arrive_time.time'), ('pm', 'I-arrive_time.time'), ('and', 'O'), ('is', 'O'), ('nonstop', 'B-flight_stop')]\n",
      "\n",
      "\n",
      "[('lowest', 'B-cost_relative'), ('fare', 'O'), ('from', 'O'), ('san', 'B-fromloc.city_name'), ('francisco', 'I-fromloc.city_name'), ('to', 'O'), ('los', 'B-toloc.city_name'), ('angeles', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('a', 'O'), ('morning', 'B-depart_time.period_of_day'), ('flight', 'O'), ('from', 'O'), ('milwaukee', 'B-fromloc.city_name'), ('to', 'O'), ('denver', 'B-toloc.city_name'), ('colorado', 'B-toloc.state_name'), ('please', 'O')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('flights', 'O'), ('from', 'O'), ('washington', 'B-fromloc.city_name'), ('to', 'O'), ('boston', 'B-toloc.city_name'), ('on', 'O'), ('friday', 'B-depart_date.day_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('from', 'O'), ('tacoma', 'B-fromloc.city_name'), ('to', 'O'), ('orlando', 'B-toloc.city_name'), ('on', 'O'), ('saturday', 'B-depart_date.day_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('the', 'O'), ('prices', 'O'), ('of', 'O'), ('all', 'O'), ('flights', 'O'), ('from', 'O'), ('atlanta', 'B-fromloc.city_name'), ('to', 'O'), ('washington', 'B-toloc.city_name'), ('dc', 'B-toloc.state_code')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('go', 'O'), ('from', 'O'), ('baltimore', 'B-fromloc.city_name'), ('to', 'O'), ('newark', 'B-toloc.city_name'), ('wednesday', 'B-depart_date.day_name'), ('morning', 'B-depart_time.period_of_day')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('from', 'O'), ('pittsburgh', 'B-fromloc.city_name'), ('to', 'O'), ('atlanta', 'B-toloc.city_name'), ('on', 'O'), ('wednesday', 'B-depart_date.day_name'), ('morning', 'B-depart_time.period_of_day'), ('serves', 'O'), ('breakfast', 'B-meal_description')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('is', 'O'), ('the', 'O'), ('least', 'B-cost_relative'), ('expensive', 'I-cost_relative'), ('one', 'B-round_trip'), ('way', 'I-round_trip'), ('fare', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('pittsburgh', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('all', 'O'), ('flights', 'O'), ('and', 'O'), ('fares', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('san', 'B-toloc.city_name'), ('francisco', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('is', 'O'), ('bwi', 'B-airport_code'), ('washington', 'B-city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('ground', 'O'), ('transportation', 'O'), ('is', 'O'), ('available', 'O'), ('at', 'O'), ('denver', 'B-airport_name'), ('airport', 'I-airport_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('are', 'O'), ('the', 'O'), ('flights', 'O'), ('from', 'O'), ('dallas', 'B-fromloc.city_name'), ('to', 'O'), ('san', 'B-toloc.city_name'), ('francisco', 'I-toloc.city_name'), ('on', 'O'), ('tuesday', 'B-depart_date.day_name'), ('october', 'B-depart_date.month_name'), ('first', 'B-depart_date.day_number')]\n",
      "\n",
      "\n",
      "[('list', 'O'), ('number', 'O'), ('of', 'O'), ('people', 'O'), ('that', 'O'), ('can', 'O'), ('be', 'O'), ('<UNK>', 'O'), ('on', 'O'), ('each', 'O'), ('type', 'O'), ('of', 'O'), ('plane', 'O'), ('that', 'O'), ('flies', 'O'), ('between', 'O'), ('pittsburgh', 'B-fromloc.city_name'), ('and', 'O'), ('baltimore', 'B-toloc.city_name')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing a few randomly chosen sentences and the corresponding labels (tagged entities)\n",
    "for i in random.sample(range(len(train_x)), 20):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[i]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[i]))\n",
    "    print(list(zip(w, l)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function which takes in an index and returns the corresponding query with its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query(index):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[index]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[index]))\n",
    "    s = list(zip(w, l))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('on', 'O'),\n",
       " ('<UNK>', 'B-airline_name'),\n",
       " ('air', 'I-airline_name'),\n",
       " ('how', 'O'),\n",
       " ('many', 'O'),\n",
       " ('flights', 'O'),\n",
       " ('leaving', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('july', 'B-depart_date.month_name'),\n",
       " ('twenty', 'B-depart_date.day_number'),\n",
       " ('seventh', 'I-depart_date.day_number'),\n",
       " ('to', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('nonstop', 'B-flight_stop')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3925)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some queries specify stopover cities, such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'O'),\n",
       " ('there', 'O'),\n",
       " ('a', 'O'),\n",
       " ('flight', 'O'),\n",
       " ('between', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('and', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('stopover', 'O'),\n",
       " ('in', 'O'),\n",
       " ('dallas', 'B-stoploc.city_name'),\n",
       " ('fort', 'I-stoploc.city_name'),\n",
       " ('worth', 'I-stoploc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('twa', 'B-airline_code')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this dataset, queries are far more complex (in terms of number of labels, variety in the sentence structures etc.) and thus we cannot  write simple hand-written rules to extract chunks such as to_from_city, types_of_meals etc. \n",
    "\n",
    "Thus, we need to train probabilistic models such as CRFs, HMMs etc. to tag each word with its corresponding entity label.\n",
    "\n",
    "We'll use the training and validation sets ```train_x``` and ```valid_x``` as to tune the model, and finaly use test set to measure the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for NER\n",
    "\n",
    "Let's experiment with a few different models for labelling words with named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging sentences\n",
    "# takes in a list of sentences and returns a list of POS-tagged sentences\n",
    "# in the form (word, tag)\n",
    "\n",
    "def pos_tag(sent_list):\n",
    "    pos_tags = []    \n",
    "    for sent in sent_list:\n",
    "        tagged_words = nltk.pos_tag([id_to_words[val] for val in sent])\n",
    "        pos_tags.append(tagged_words)\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagging train, validation and test sets\n",
    "train_pos = pos_tag(train_x)\n",
    "valid_pos = pos_tag(val_x)\n",
    "test_pos = pos_tag(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('can', 'MD'),\n",
       " ('i', 'VB'),\n",
       " ('get', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('rental', 'JJ'),\n",
       " ('car', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('dallas', 'NN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at tags of some randomly chosen queries\n",
    "# notice that most cities after 'TO' are tagged as VB\n",
    "i = random.randrange(len(train_pos))\n",
    "train_pos[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need the entity labels of each word along with the POS tags, for e.g. in this format:\n",
    "```[('New', 'NNP', u'B-GPE'), ('York', 'NNP', u'I-GPE'), ('is', 'VBZ', u'O'), ('my', 'PRP$', u'O'), ('favorite', 'JJ', u'O'), ('city', 'NN', u'O')]```\n",
    "\n",
    "Let's convert the training and validation sentences to this form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create (word, pos_tag, iob_label) tuples for a given dataset\n",
    "def create_word_pos_label(pos_tagged_data, labels):\n",
    "    iob_labels = []\n",
    "    for sent in list(zip(pos_tagged_data, labels)):\n",
    "        pos = sent[0]\n",
    "        labels = sent[1]\n",
    "        l = list(zip(pos, labels))\n",
    "        tuple_3 = [(i[0][0], i[0][1], id_to_labels[i[1]]) for i in l]\n",
    "        iob_labels.append(tuple_3)\n",
    "    return iob_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('what', 'WP', 'O'),\n",
       "  ('flights', 'NNS', 'O'),\n",
       "  ('leave', 'VBP', 'O'),\n",
       "  ('atlanta', 'VBN', 'B-fromloc.city_name'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('about', 'RB', 'B-depart_time.time_relative'),\n",
       "  ('DIGIT', 'NNP', 'B-depart_time.time'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('afternoon', 'NN', 'B-depart_time.period_of_day'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('arrive', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('san', 'JJ', 'B-toloc.city_name'),\n",
       "  ('francisco', 'NN', 'I-toloc.city_name')],\n",
       " [('what', 'WP', 'O'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('abbreviation', 'NN', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('canadian', 'JJ', 'B-airline_name'),\n",
       "  ('airlines', 'NNS', 'I-airline_name'),\n",
       "  ('international', 'JJ', 'I-airline_name')]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = create_word_pos_label(train_pos, train_label)\n",
    "train_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('give', 'VB', 'O'),\n",
       " ('me', 'PRP', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('continental', 'JJ', 'B-airline_name'),\n",
       " ('flights', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('chicago', 'NN', 'B-fromloc.city_name'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('seattle', 'VB', 'B-toloc.city_name'),\n",
       " ('on', 'IN', 'O'),\n",
       " ('saturday', 'JJ', 'B-depart_date.day_name'),\n",
       " ('morning', 'NN', 'B-depart_time.period_of_day')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some sample training sentences\n",
    "train_labels[random.randrange(len(train_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for validation and test data\n",
    "valid_labels = create_word_pos_label(valid_pos, val_label)\n",
    "test_labels = create_word_pos_label(test_pos, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Tree Format\n",
    "\n",
    "Let's now convert the sentences into a tree format, which is needed by NLTK to train taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  i/JJ\n",
      "  'd/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  know/VB\n",
      "  the/DT\n",
      "  (flight_mod earliest/JJS)\n",
      "  flight/NN\n",
      "  from/IN\n",
      "  (fromloc.city_name boston/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name atlanta/VB))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "from nltk import conlltags2tree, tree2conlltags\n",
    "\n",
    "# converting a sample sentence to a tree\n",
    "tree = conlltags2tree(train_labels[2])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert all training sentences to trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training, validation and test datasets to tree format\n",
    "train_trees = [conlltags2tree(sent) for sent in train_labels]\n",
    "valid_trees = [conlltags2tree(sent) for sent in valid_labels]\n",
    "test_trees = [conlltags2tree(sent) for sent in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  i/JJ\n",
      "  'd/MD\n",
      "  like/VB\n",
      "  information/NN\n",
      "  on/IN\n",
      "  (fromloc.city_name boston/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name washington/VB))\n"
     ]
    }
   ],
   "source": [
    "# print some sample training trees\n",
    "print(train_trees[random.randrange(len(train_trees))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try building some parsers. \n",
    "\n",
    "### Regex Based Parsers\n",
    "\n",
    "Let's start with a dummy parser - one which tags every token as an 'O'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  63.6%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# a dummy chunk parser - tags every word as 'O'\n",
    "cp = nltk.RegexpParser(r'')\n",
    "print(cp.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tell us that about 63% of the tokens are tagged as 'O', i.e. they are not a named entity of any type. The precision, recall etc. are zero because we did not find any chunks at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Chunker\n",
    "\n",
    "Let's now try a unigram chunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram chunker\n",
    "\n",
    "from nltk import ChunkParserI\n",
    "\n",
    "class UnigramChunker(ChunkParserI):    \n",
    "    def __init__(self, train_sents):\n",
    "        # convert train sents from tree format to tags\n",
    "        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        \n",
    "        # convert to tree again\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  66.3%%\n",
      "    Precision:     37.5%%\n",
      "    Recall:        18.5%%\n",
      "    F-Measure:     24.8%%\n"
     ]
    }
   ],
   "source": [
    "# unigram chunker \n",
    "unigram_chunker = UnigramChunker(train_trees)\n",
    "print(unigram_chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, precision and recall have of course improved compared to the previous dummy parser. Let's also look at what the unigram parser has learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CC', 'O'), ('CD', 'B-round_trip'), ('DT', 'O'), ('EX', 'O'), ('FW', 'B-fromloc.city_name'), ('IN', 'O'), ('JJ', 'O'), ('JJR', 'B-cost_relative'), ('JJS', 'B-cost_relative'), ('MD', 'O'), ('NN', 'O'), ('NNP', 'B-depart_time.time'), ('NNS', 'O'), ('PDT', 'O'), ('POS', 'O'), ('PRP', 'O'), ('PRP$', 'O'), ('RB', 'O'), ('RBR', 'B-cost_relative'), ('RBS', 'B-cost_relative'), ('RP', 'O'), ('TO', 'O'), ('VB', 'B-toloc.city_name'), ('VBD', 'O'), ('VBG', 'O'), ('VBN', 'O'), ('VBP', 'O'), ('VBZ', 'O'), ('WDT', 'O'), ('WP', 'O'), ('WRB', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# printing the most likely IOB tags for each POS tag\n",
    "\n",
    "# extract the list of pos tags\n",
    "postags = sorted(set([pos for sent in train_trees for (word, pos) in sent.leaves()]))\n",
    "\n",
    "# for each tag, assign the most likely IOB label\n",
    "print(unigram_chunker.tagger.tag(postags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unigram tagger has learnt that most pos tags are indeed an 'O', i.e. don't form an entity. Some interesting patterns it has learnt are:\n",
    "- JJR, JJS (relative adjectives), are most likely B-cost_relative (e.g. cheapest, cheaper)\n",
    "- NNP is most likely to be B-depart_time.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Chunker\n",
    "\n",
    "Let's try a bigram chunker as well - we just need to change the ```UnigramTagger``` to ```BigramTagger```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram tagger\n",
    "\n",
    "class BigramChunker(ChunkParserI):    \n",
    "    def __init__(self, train_sents):\n",
    "        # convert train sents from tree format to tags\n",
    "        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        \n",
    "        # convert to tree again\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  70.6%%\n",
      "    Precision:     43.5%%\n",
      "    Recall:        38.8%%\n",
      "    F-Measure:     41.0%%\n"
     ]
    }
   ],
   "source": [
    "# unigram chunker \n",
    "bigram_chunker = BigramChunker(train_trees)\n",
    "print(bigram_chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have improved significantly from unigram to bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Gazetteer to Lookup Cities and States\n",
    "\n",
    "URL: https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State short</th>\n",
       "      <th>State full</th>\n",
       "      <th>County</th>\n",
       "      <th>City alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Internal Revenue Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Holtsville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>URB San Joaquin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Jard De Adjuntas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Colinas Del Gigante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State short   State full    County                City alias\n",
       "0  Holtsville          NY     New York   SUFFOLK  Internal Revenue Service\n",
       "1  Holtsville          NY     New York   SUFFOLK                Holtsville\n",
       "2    Adjuntas          PR  Puerto Rico  ADJUNTAS           URB San Joaquin\n",
       "3    Adjuntas          PR  Puerto Rico  ADJUNTAS          Jard De Adjuntas\n",
       "4    Adjuntas          PR  Puerto Rico  ADJUNTAS       Colinas Del Gigante"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading a file containing list of US cities, states and counties\n",
    "us_cities = pd.read_csv(\"us_cities_states_counties.csv\", sep=\"|\")\n",
    "us_cities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing cities, states and counties as sets\n",
    "cities = set(us_cities['City'].str.lower())\n",
    "states = set(us_cities['State full'].str.lower())\n",
    "counties = set(us_cities['County'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18854\n",
      "62\n",
      "1932\n"
     ]
    }
   ],
   "source": [
    "print(len(cities))\n",
    "print(len(states))\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to look up a given word in cities, states, county\n",
    "def gazetteer_lookup(word):\n",
    "    return (word in cities, word in states, word in counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, True)\n",
      "(False, True, True)\n",
      "(True, False, True)\n"
     ]
    }
   ],
   "source": [
    "# sample lookups\n",
    "print(gazetteer_lookup('washington'))\n",
    "print(gazetteer_lookup('utah'))\n",
    "print(gazetteer_lookup('philadelphia'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Based Chunkers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveNPChunkTagger(nltk.TaggerI): \n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = npchunk_features(untagged_sent, i, history) \n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = npchunk_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)\n",
    "\n",
    "class ConsecutiveNPChunker(nltk.ChunkParserI): \n",
    "    def __init__(self, train_sents):\n",
    "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
    "                         nltk.chunk.tree2conlltags(sent)]\n",
    "                        for sent in train_sents]\n",
    "        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        tagged_sents = self.tagger.tag(sentence)\n",
    "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features for a given word i in a given sentence \n",
    "# history refers to the previous POS tags in the sentence\n",
    "def npchunk_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    # the first word has both previous word and previous tag undefined\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "\n",
    "    # gazetteer lookup features (see section below)\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "\n",
    "    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word,\n",
    "           'word_is_city': gazetteer[0],\n",
    "           'word_is_state': gazetteer[1],\n",
    "           'word_is_county': gazetteer[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('flights', 'NNS'),\n",
       " ('leave', 'VBP'),\n",
       " ('atlanta', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('about', 'RB'),\n",
       " ('DIGIT', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('afternoon', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('arrive', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('san', 'JJ'),\n",
       " ('francisco', 'NN')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example features for a given sentence\n",
    "sent_pos = train_pos[0]\n",
    "sent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 'WP', 'prevpos': '<START>', 'word': 'what', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NNS', 'prevpos': 'WP', 'word': 'flights', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'VBP', 'prevpos': 'NNS', 'word': 'leave', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'VBN', 'prevpos': 'VBP', 'word': 'atlanta', 'word_is_city': True, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'VBN', 'word': 'at', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'RB', 'prevpos': 'IN', 'word': 'about', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NNP', 'prevpos': 'RB', 'word': 'DIGIT', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'NNP', 'word': 'in', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'DT', 'prevpos': 'IN', 'word': 'the', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'DT', 'word': 'afternoon', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'CC', 'prevpos': 'NN', 'word': 'and', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'CC', 'word': 'arrive', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'NN', 'word': 'in', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'JJ', 'prevpos': 'IN', 'word': 'san', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'JJ', 'word': 'francisco', 'word_is_city': True, 'word_is_state': False, 'word_is_county': False}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# example features for a sentence\n",
    "for i in range(len(sent_pos)):\n",
    "    print(npchunk_features(sent_pos, i, history=[]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the chunker \n",
    "chunker = ConsecutiveNPChunker(train_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  91.7%%\n",
      "    Precision:     75.3%%\n",
      "    Recall:        81.8%%\n",
      "    F-Measure:     78.4%%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the chunker\n",
    "print(chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results have improved significantly compared to the basic unigram/bigram chunkers, and they may improve further if we create better features.\n",
    "\n",
    "For example, if the word is 'DIGIT' (numbers are labelled as 'DIGIT' in this dataset), we can have a feature which indicates that (see example below). In this dataset, 4-digit numbers are encoded as 'DIGITDIGITDIGITDIGIT'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('DIGITDIGITDIGIT', 'NNP'),\n",
       " ('flight', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('denver', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('san', 'VB'),\n",
       " ('francisco', 'NN')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of 'DIGITDIGIT'\n",
    "train_pos[1326]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some of these features and see if the performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features for a given word i in a given sentence \n",
    "# history refers to the previous POS tags in the sentence\n",
    "def npchunk_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    # the first word has both previous word and previous tag undefined\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "        \n",
    "    if i == len(sentence)-1:\n",
    "        nextword, nextpos = '<END>', '<END>'\n",
    "    else:\n",
    "        nextword, nextpos = sentence[i+1]\n",
    "\n",
    "    # gazetteer lookup features (see section below)\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "\n",
    "    # adding word_is_digit feature (boolean)\n",
    "    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word, \n",
    "           'word_is_city': gazetteer[0],\n",
    "           'word_is_state': gazetteer[1],\n",
    "           'word_is_county': gazetteer[2],\n",
    "           'word_is_digit': word in 'DIGITDIGITDIGIT', \n",
    "           'nextword': nextword, \n",
    "           'nextpos': nextpos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  91.7%%\n",
      "    Precision:     75.9%%\n",
      "    Recall:        85.1%%\n",
      "    F-Measure:     80.3%%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate the chunker \n",
    "chunker = ConsecutiveNPChunker(train_trees)\n",
    "print(chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ChunkParse score:\n",
    "#     IOB Accuracy:  92.7%%\n",
    "#     Precision:     78.1%%\n",
    "#     Recall:        84.9%%\n",
    "#     F-Measure:     81.4%%\n",
    "\n",
    "# ChunkParse score:\n",
    "#     IOB Accuracy:  91.7%%\n",
    "#     Precision:     75.5%%\n",
    "#     Recall:        82.0%%\n",
    "#     F-Measure:     78.6%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF Tagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('flights', 'NNS', 'O'),\n",
       " ('leave', 'VBP', 'O'),\n",
       " ('atlanta', 'VBN', 'B-fromloc.city_name'),\n",
       " ('at', 'IN', 'O'),\n",
       " ('about', 'RB', 'B-depart_time.time_relative'),\n",
       " ('DIGIT', 'NNP', 'B-depart_time.time'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('afternoon', 'NN', 'B-depart_time.period_of_day'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('arrive', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('san', 'JJ', 'B-toloc.city_name'),\n",
       " ('francisco', 'NN', 'I-toloc.city_name')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structure of train/validation data\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to extract features from a given sentence. This is similar to the ```npchunk_features()``` function defined above, but we'll add some new features as well such as the suffix of the word (upto the last 4 characters), prefix (upto first 4 characters) etc.\n",
    "\n",
    "The list of features we'll extract is as follows:\n",
    "```\n",
    "{\n",
    "            'word':word,\n",
    "            'pos': pos, \n",
    "            'prevword': prevword,\n",
    "            'prevpos': prevpos,  \n",
    "            'nextword': nextword, \n",
    "            'nextpos': nextpos,\n",
    "            'word_is_city': gazetteer[0],\n",
    "            'word_is_state': gazetteer[1],\n",
    "            'word_is_county': gazetteer[2],\n",
    "            'word_is_digit': word in 'DIGITDIGITDIGIT',\n",
    "            'suff_1': suff_1,  \n",
    "            'suff_2': suff_2,  \n",
    "            'suff_3': suff_3,  \n",
    "            'suff_4': suff_4, \n",
    "            'pref_1': pref_1,  \n",
    "            'pref_2': pref_2,  \n",
    "            'pref_3': pref_3, \n",
    "            'pref_4': pref_4 \n",
    "\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other features to consider\n",
    "\n",
    "# airline code\n",
    "# airline name\n",
    "# day name (monday/tuesday etc.) i=1847, 2769\n",
    "# o'clock (word shape): i=379\n",
    "\n",
    "# i=random.randrange(len(train_labels))\n",
    "# train_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from a given sentence\n",
    "def word_features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    pos = sent[i][1]\n",
    "    \n",
    "    # first word\n",
    "    if i==0:\n",
    "        prevword = '<START>'\n",
    "        prevpos = '<START>'\n",
    "    else:\n",
    "        prevword = sent[i-1][0]\n",
    "        prevpos = sent[i-1][1]\n",
    "    \n",
    "    # last word\n",
    "    if i == len(sent)-1:\n",
    "        nextword = '<END>'\n",
    "        nextpos = '<END>'\n",
    "    else:\n",
    "        nextword = sent[i+1][0]\n",
    "        nextpos = sent[i+1][1]\n",
    "    \n",
    "    # word is in gazetteer\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "    \n",
    "    # suffixes and prefixes\n",
    "    pref_1, pref_2, pref_3, pref_4 = word[:1], word[:2], word[:3], word[:4]\n",
    "    suff_1, suff_2, suff_3, suff_4 = word[-1:], word[-2:], word[-3:], word[-4:]\n",
    "    \n",
    "    return {'word':word,\n",
    "            'pos': pos, \n",
    "            'prevword': prevword,\n",
    "            'prevpos': prevpos,  \n",
    "            'nextword': nextword, \n",
    "            'nextpos': nextpos,\n",
    "            'word_is_city': gazetteer[0],\n",
    "            'word_is_state': gazetteer[1],\n",
    "            'word_is_county': gazetteer[2],\n",
    "            'word_is_digit': word in 'DIGITDIGITDIGIT',\n",
    "            'suff_1': suff_1,  \n",
    "            'suff_2': suff_2,  \n",
    "            'suff_3': suff_3,  \n",
    "            'suff_4': suff_4, \n",
    "            'pref_1': pref_1,  \n",
    "            'pref_2': pref_2,  \n",
    "            'pref_3': pref_3, \n",
    "            'pref_4': pref_4 }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nextpos': 'IN',\n",
       " 'nextword': 'at',\n",
       " 'pos': 'VBN',\n",
       " 'pref_1': 'a',\n",
       " 'pref_2': 'at',\n",
       " 'pref_3': 'atl',\n",
       " 'pref_4': 'atla',\n",
       " 'prevpos': 'VBP',\n",
       " 'prevword': 'leave',\n",
       " 'suff_1': 'a',\n",
       " 'suff_2': 'ta',\n",
       " 'suff_3': 'nta',\n",
       " 'suff_4': 'anta',\n",
       " 'word': 'atlanta',\n",
       " 'word_is_city': True,\n",
       " 'word_is_county': False,\n",
       " 'word_is_digit': False,\n",
       " 'word_is_state': False}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example features\n",
    "word_features(train_labels[0], i=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a few more functions to extract featrues, labels, words from sentences\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word_features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation and test sets\n",
    "X_train = [sent2features(s) for s in train_labels]\n",
    "y_train = [sent2labels(s) for s in train_labels]\n",
    "\n",
    "X_valid = [sent2features(s) for s in valid_labels]\n",
    "y_valid = [sent2labels(s) for s in valid_labels]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_labels]\n",
    "y_test = [sent2labels(s) for s in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nextpos': 'NNS',\n",
       "  'nextword': 'flights',\n",
       "  'pos': 'WP',\n",
       "  'pref_1': 'w',\n",
       "  'pref_2': 'wh',\n",
       "  'pref_3': 'wha',\n",
       "  'pref_4': 'what',\n",
       "  'prevpos': '<START>',\n",
       "  'prevword': '<START>',\n",
       "  'suff_1': 't',\n",
       "  'suff_2': 'at',\n",
       "  'suff_3': 'hat',\n",
       "  'suff_4': 'what',\n",
       "  'word': 'what',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False},\n",
       " {'nextpos': 'VBP',\n",
       "  'nextword': 'leave',\n",
       "  'pos': 'NNS',\n",
       "  'pref_1': 'f',\n",
       "  'pref_2': 'fl',\n",
       "  'pref_3': 'fli',\n",
       "  'pref_4': 'flig',\n",
       "  'prevpos': 'WP',\n",
       "  'prevword': 'what',\n",
       "  'suff_1': 's',\n",
       "  'suff_2': 'ts',\n",
       "  'suff_3': 'hts',\n",
       "  'suff_4': 'ghts',\n",
       "  'word': 'flights',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False},\n",
       " {'nextpos': 'VBN',\n",
       "  'nextword': 'atlanta',\n",
       "  'pos': 'VBP',\n",
       "  'pref_1': 'l',\n",
       "  'pref_2': 'le',\n",
       "  'pref_3': 'lea',\n",
       "  'pref_4': 'leav',\n",
       "  'prevpos': 'NNS',\n",
       "  'prevword': 'flights',\n",
       "  'suff_1': 'e',\n",
       "  'suff_2': 've',\n",
       "  'suff_3': 'ave',\n",
       "  'suff_4': 'eave',\n",
       "  'word': 'leave',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is a list of sentences within which each feature has a corresponding dict of features\n",
    "# first few words of the first sentence in X_train\n",
    "X_train[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implementing sklearn-CRF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-fromloc.city_name',\n",
       " 'B-depart_time.time_relative',\n",
       " 'B-depart_time.time',\n",
       " 'B-depart_time.period_of_day',\n",
       " 'B-toloc.city_name']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'O' from the labels\n",
    "labels =list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.909517940883257"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions \n",
    "y_pred = crf.predict(X_valid)\n",
    "metrics.flat_f1_score(y_valid, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "             B-aircraft_code      1.000     0.667     0.800        33\n",
      "              B-airline_code      0.967     0.853     0.906        34\n",
      "              B-airline_name      0.990     0.980     0.985       101\n",
      "              I-airline_name      0.969     0.969     0.969        65\n",
      "              B-airport_code      0.400     0.444     0.421         9\n",
      "              B-airport_name      0.778     0.333     0.467        21\n",
      "              I-airport_name      0.833     0.345     0.488        29\n",
      " B-arrive_date.date_relative      0.667     1.000     0.800         2\n",
      "      B-arrive_date.day_name      0.750     0.545     0.632        11\n",
      "    B-arrive_date.day_number      0.000     0.000     0.000         6\n",
      "    I-arrive_date.day_number      0.000     0.000     0.000         0\n",
      "    B-arrive_date.month_name      0.000     0.000     0.000         6\n",
      "      B-arrive_time.end_time      0.000     0.000     0.000         8\n",
      "      I-arrive_time.end_time      0.000     0.000     0.000         8\n",
      "    B-arrive_time.period_mod      0.000     0.000     0.000         0\n",
      " B-arrive_time.period_of_day      0.000     0.000     0.000         6\n",
      " I-arrive_time.period_of_day      0.000     0.000     0.000         0\n",
      "    B-arrive_time.start_time      0.750     0.750     0.750         8\n",
      "    I-arrive_time.start_time      0.000     0.000     0.000         1\n",
      "          B-arrive_time.time      0.794     0.794     0.794        34\n",
      "          I-arrive_time.time      0.824     0.800     0.812        35\n",
      " B-arrive_time.time_relative      0.897     0.839     0.867        31\n",
      "                 B-city_name      0.556     0.351     0.430        57\n",
      "                 I-city_name      0.667     0.333     0.444        30\n",
      "                B-class_type      0.960     1.000     0.980        24\n",
      "                I-class_type      1.000     1.000     1.000        17\n",
      "                   B-connect      1.000     1.000     1.000         6\n",
      "             B-cost_relative      1.000     0.973     0.986        37\n",
      "             I-cost_relative      1.000     0.667     0.800         3\n",
      "                  B-day_name      0.000     0.000     0.000         2\n",
      "                B-day_number      0.000     0.000     0.000         0\n",
      "                 B-days_code      1.000     1.000     1.000         1\n",
      " B-depart_date.date_relative      0.941     0.941     0.941        17\n",
      "      B-depart_date.day_name      0.959     0.986     0.972       212\n",
      "    B-depart_date.day_number      0.902     1.000     0.948        55\n",
      "    I-depart_date.day_number      1.000     1.000     1.000        15\n",
      "    B-depart_date.month_name      0.902     0.982     0.940        56\n",
      "B-depart_date.today_relative      1.000     1.000     1.000         9\n",
      "I-depart_date.today_relative      0.000     0.000     0.000         0\n",
      "          B-depart_date.year      1.000     1.000     1.000         3\n",
      "      B-depart_time.end_time      0.222     0.667     0.333         3\n",
      "      I-depart_time.end_time      0.222     0.667     0.333         3\n",
      "    B-depart_time.period_mod      0.714     1.000     0.833         5\n",
      " B-depart_time.period_of_day      0.930     0.923     0.927       130\n",
      " I-depart_time.period_of_day      1.000     1.000     1.000         1\n",
      "    B-depart_time.start_time      0.500     0.333     0.400         3\n",
      "    I-depart_time.start_time      0.500     1.000     0.667         1\n",
      "          B-depart_time.time      0.761     0.895     0.823        57\n",
      "          I-depart_time.time      0.868     0.885     0.876        52\n",
      " B-depart_time.time_relative      0.924     0.938     0.931        65\n",
      " I-depart_time.time_relative      0.000     0.000     0.000         1\n",
      "                   B-economy      1.000     1.000     1.000         6\n",
      "                   I-economy      0.000     0.000     0.000         0\n",
      "               B-fare_amount      1.000     1.000     1.000         2\n",
      "               I-fare_amount      1.000     1.000     1.000         2\n",
      "           B-fare_basis_code      0.889     0.941     0.914        17\n",
      "           I-fare_basis_code      0.000     0.000     0.000         0\n",
      "               B-flight_days      1.000     1.000     1.000        10\n",
      "                B-flight_mod      1.000     0.958     0.979        24\n",
      "                I-flight_mod      0.000     0.000     0.000         6\n",
      "             B-flight_number      0.917     1.000     0.957        11\n",
      "               B-flight_stop      1.000     1.000     1.000        21\n",
      "               I-flight_stop      0.000     0.000     0.000         0\n",
      "               B-flight_time      1.000     1.000     1.000         1\n",
      "               I-flight_time      1.000     1.000     1.000         1\n",
      "      B-fromloc.airport_code      0.714     1.000     0.833         5\n",
      "      B-fromloc.airport_name      0.522     1.000     0.686        12\n",
      "      I-fromloc.airport_name      0.484     1.000     0.652        15\n",
      "         B-fromloc.city_name      0.979     0.999     0.989       704\n",
      "         I-fromloc.city_name      0.922     1.000     0.959       177\n",
      "        B-fromloc.state_code      1.000     1.000     1.000        23\n",
      "        B-fromloc.state_name      1.000     0.824     0.903        17\n",
      "        I-fromloc.state_name      1.000     1.000     1.000         1\n",
      "                      B-meal      0.941     1.000     0.970        16\n",
      "                 B-meal_code      0.000     0.000     0.000         1\n",
      "                 I-meal_code      0.000     0.000     0.000         0\n",
      "          B-meal_description      1.000     0.900     0.947        10\n",
      "          I-meal_description      0.000     0.000     0.000         0\n",
      "                       B-mod      0.000     0.000     0.000         2\n",
      "                B-month_name      0.000     0.000     0.000         0\n",
      "                        B-or      0.500     1.000     0.667         3\n",
      "             B-period_of_day      0.000     0.000     0.000         4\n",
      "          B-restriction_code      1.000     0.750     0.857         4\n",
      "          I-restriction_code      1.000     1.000     1.000         3\n",
      " B-return_date.date_relative      0.000     0.000     0.000         3\n",
      " I-return_date.date_relative      0.000     0.000     0.000         3\n",
      "      B-return_date.day_name      0.000     0.000     0.000         2\n",
      "    B-return_date.day_number      0.000     0.000     0.000         0\n",
      "    B-return_date.month_name      0.000     0.000     0.000         0\n",
      "B-return_date.today_relative      0.000     0.000     0.000         0\n",
      "I-return_date.today_relative      0.000     0.000     0.000         0\n",
      "    B-return_time.period_mod      0.000     0.000     0.000         0\n",
      " B-return_time.period_of_day      0.000     0.000     0.000         0\n",
      "                B-round_trip      1.000     0.973     0.986        73\n",
      "                I-round_trip      1.000     1.000     1.000        71\n",
      "                B-state_code      0.500     1.000     0.667         1\n",
      "                B-state_name      0.000     0.000     0.000         9\n",
      "      B-stoploc.airport_name      0.000     0.000     0.000         0\n",
      "         B-stoploc.city_name      0.464     0.650     0.542        20\n",
      "         I-stoploc.city_name      0.545     0.600     0.571        10\n",
      "        B-stoploc.state_code      0.000     0.000     0.000         0\n",
      "                      B-time      0.000     0.000     0.000         0\n",
      "                      I-time      0.000     0.000     0.000         0\n",
      "             B-time_relative      0.000     0.000     0.000         0\n",
      "            B-today_relative      0.000     0.000     0.000         0\n",
      "            I-today_relative      0.000     0.000     0.000         0\n",
      "        B-toloc.airport_code      1.000     0.500     0.667         4\n",
      "        B-toloc.airport_name      0.750     1.000     0.857         3\n",
      "        I-toloc.airport_name      0.600     1.000     0.750         3\n",
      "           B-toloc.city_name      0.965     0.966     0.966       716\n",
      "           I-toloc.city_name      0.948     0.962     0.955       265\n",
      "        B-toloc.country_name      0.000     0.000     0.000         1\n",
      "          B-toloc.state_code      1.000     0.944     0.971        18\n",
      "          B-toloc.state_name      0.852     0.821     0.836        28\n",
      "          I-toloc.state_name      1.000     1.000     1.000         1\n",
      "            B-transport_type      1.000     1.000     1.000        10\n",
      "            I-transport_type      0.000     0.000     0.000         1\n",
      "\n",
      "                 avg / total      0.912     0.915     0.910      3653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise scores\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "\n",
    "# parameters to tune\n",
    "params_space = {\n",
    "    'c1': [0.01, 0.1, 1],\n",
    "    'c2': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = scorers.make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...e,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'c1': [0.01, 0.1, 1], 'c2': [0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-fromloc.city_name', 'B-depart_time.time_relative', 'B-depart_time.time', 'B-depart_time.period_of_day', 'B-toloc.city_name', 'I-toloc.city_name', 'B-airline_name', 'I-airline_name', 'B-flight_mod', 'B-cost_relative', 'B-round_trip', 'I-...te_code', 'I-arrive_time.start_time', 'B-state_name', 'I-today_relative', 'B-stoploc.airport_name']),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search\n",
    "rs = GridSearchCV(crf, \n",
    "                  params_space,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=-1,\n",
    "                  scoring=f1_scorer, \n",
    "                  return_train_score=True)\n",
    "# fit\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_c1</th>\n",
       "      <th>param_c2</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204.841608</td>\n",
       "      <td>0.764602</td>\n",
       "      <td>0.929098</td>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'c1': 0.01, 'c2': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.930426</td>\n",
       "      <td>0.978361</td>\n",
       "      <td>0.922370</td>\n",
       "      <td>0.980400</td>\n",
       "      <td>0.934504</td>\n",
       "      <td>0.979812</td>\n",
       "      <td>16.471836</td>\n",
       "      <td>0.117479</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201.370505</td>\n",
       "      <td>0.771143</td>\n",
       "      <td>0.930745</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'c1': 0.01, 'c2': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.930870</td>\n",
       "      <td>0.975267</td>\n",
       "      <td>0.926590</td>\n",
       "      <td>0.977576</td>\n",
       "      <td>0.934779</td>\n",
       "      <td>0.977806</td>\n",
       "      <td>15.078049</td>\n",
       "      <td>0.045171</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209.234534</td>\n",
       "      <td>0.833075</td>\n",
       "      <td>0.917357</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'c1': 0.01, 'c2': 1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.920278</td>\n",
       "      <td>0.950655</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.949025</td>\n",
       "      <td>0.918695</td>\n",
       "      <td>0.949209</td>\n",
       "      <td>23.225543</td>\n",
       "      <td>0.035932</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216.224102</td>\n",
       "      <td>0.916984</td>\n",
       "      <td>0.930336</td>\n",
       "      <td>0.978921</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'c1': 0.1, 'c2': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.931663</td>\n",
       "      <td>0.978314</td>\n",
       "      <td>0.923990</td>\n",
       "      <td>0.979166</td>\n",
       "      <td>0.935359</td>\n",
       "      <td>0.979282</td>\n",
       "      <td>20.204042</td>\n",
       "      <td>0.174685</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.435544</td>\n",
       "      <td>0.957883</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'c1': 0.1, 'c2': 0.1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932268</td>\n",
       "      <td>0.973995</td>\n",
       "      <td>0.926484</td>\n",
       "      <td>0.975931</td>\n",
       "      <td>0.936914</td>\n",
       "      <td>0.976143</td>\n",
       "      <td>20.432426</td>\n",
       "      <td>0.142685</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>214.062770</td>\n",
       "      <td>0.925102</td>\n",
       "      <td>0.916126</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'c1': 0.1, 'c2': 1}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.917787</td>\n",
       "      <td>0.948426</td>\n",
       "      <td>0.912097</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.918497</td>\n",
       "      <td>0.947646</td>\n",
       "      <td>17.815576</td>\n",
       "      <td>0.155170</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>211.475868</td>\n",
       "      <td>0.855619</td>\n",
       "      <td>0.920230</td>\n",
       "      <td>0.949525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'c1': 1, 'c2': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.917660</td>\n",
       "      <td>0.949051</td>\n",
       "      <td>0.920771</td>\n",
       "      <td>0.950010</td>\n",
       "      <td>0.922260</td>\n",
       "      <td>0.949515</td>\n",
       "      <td>20.671987</td>\n",
       "      <td>0.183398</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>219.004298</td>\n",
       "      <td>0.713049</td>\n",
       "      <td>0.918543</td>\n",
       "      <td>0.945967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'c1': 1, 'c2': 0.1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.914650</td>\n",
       "      <td>0.945374</td>\n",
       "      <td>0.918630</td>\n",
       "      <td>0.948256</td>\n",
       "      <td>0.922353</td>\n",
       "      <td>0.944271</td>\n",
       "      <td>20.808716</td>\n",
       "      <td>0.051280</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>181.828000</td>\n",
       "      <td>0.524956</td>\n",
       "      <td>0.904169</td>\n",
       "      <td>0.928578</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'c1': 1, 'c2': 1}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.905066</td>\n",
       "      <td>0.928574</td>\n",
       "      <td>0.905441</td>\n",
       "      <td>0.931405</td>\n",
       "      <td>0.901998</td>\n",
       "      <td>0.925755</td>\n",
       "      <td>16.748465</td>\n",
       "      <td>0.028207</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_c1  \\\n",
       "0     204.841608         0.764602         0.929098          0.979525     0.01   \n",
       "1     201.370505         0.771143         0.930745          0.976883     0.01   \n",
       "2     209.234534         0.833075         0.917357          0.949630     0.01   \n",
       "3     216.224102         0.916984         0.930336          0.978921      0.1   \n",
       "4     215.435544         0.957883         0.931887          0.975356      0.1   \n",
       "5     214.062770         0.925102         0.916126          0.947883      0.1   \n",
       "6     211.475868         0.855619         0.920230          0.949525        1   \n",
       "7     219.004298         0.713049         0.918543          0.945967        1   \n",
       "8     181.828000         0.524956         0.904169          0.928578        1   \n",
       "\n",
       "  param_c2                    params  rank_test_score  split0_test_score  \\\n",
       "0     0.01  {'c1': 0.01, 'c2': 0.01}                4           0.930426   \n",
       "1      0.1   {'c1': 0.01, 'c2': 0.1}                2           0.930870   \n",
       "2        1     {'c1': 0.01, 'c2': 1}                7           0.920278   \n",
       "3     0.01   {'c1': 0.1, 'c2': 0.01}                3           0.931663   \n",
       "4      0.1    {'c1': 0.1, 'c2': 0.1}                1           0.932268   \n",
       "5        1      {'c1': 0.1, 'c2': 1}                8           0.917787   \n",
       "6     0.01     {'c1': 1, 'c2': 0.01}                5           0.917660   \n",
       "7      0.1      {'c1': 1, 'c2': 0.1}                6           0.914650   \n",
       "8        1        {'c1': 1, 'c2': 1}                9           0.905066   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0            0.978361           0.922370            0.980400   \n",
       "1            0.975267           0.926590            0.977576   \n",
       "2            0.950655           0.913100            0.949025   \n",
       "3            0.978314           0.923990            0.979166   \n",
       "4            0.973995           0.926484            0.975931   \n",
       "5            0.948426           0.912097            0.947578   \n",
       "6            0.949051           0.920771            0.950010   \n",
       "7            0.945374           0.918630            0.948256   \n",
       "8            0.928574           0.905441            0.931405   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.934504            0.979812     16.471836        0.117479   \n",
       "1           0.934779            0.977806     15.078049        0.045171   \n",
       "2           0.918695            0.949209     23.225543        0.035932   \n",
       "3           0.935359            0.979282     20.204042        0.174685   \n",
       "4           0.936914            0.976143     20.432426        0.142685   \n",
       "5           0.918497            0.947646     17.815576        0.155170   \n",
       "6           0.922260            0.949515     20.671987        0.183398   \n",
       "7           0.922353            0.944271     20.808716        0.051280   \n",
       "8           0.901998            0.925755     16.748465        0.028207   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.005042         0.000857  \n",
       "1        0.003344         0.001147  \n",
       "2        0.003079         0.000729  \n",
       "3        0.004735         0.000432  \n",
       "4        0.004266         0.000967  \n",
       "5        0.002865         0.000385  \n",
       "6        0.001916         0.000392  \n",
       "7        0.003145         0.001680  \n",
       "8        0.001542         0.002306  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(rs.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15f00150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting CV results\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "for i, val in enumerate(params_space['c2']):\n",
    "   \n",
    "    # subplot 1/3/i\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    c2_subset = cv_results[cv_results['param_c2']==val]\n",
    "\n",
    "    plt.plot(c2_subset[\"param_c1\"], c2_subset[\"mean_test_score\"])\n",
    "    plt.plot(c2_subset[\"param_c1\"], c2_subset[\"mean_train_score\"])\n",
    "    plt.xlabel('c1')\n",
    "    plt.ylabel('Mean F-score')\n",
    "    plt.title(\"c2={0}\".format(val))\n",
    "    plt.ylim([0.80, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that at very low values of c_1, the model overfits, as shown by the difference in training and test performance. Also, the test score seems to be slightly higher for c_2 = 0.1.\n",
    "\n",
    "Let's thus choose c_1 = 0.1 and c_2 = 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a model with optimal hyperparams\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions \n",
    "\n",
    "Let's now use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9358802464006175"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'O' from the labels\n",
    "labels =list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# make predictions on validation data\n",
    "y_pred = crf.predict(X_valid)\n",
    "metrics.flat_f1_score(y_valid, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "             B-aircraft_code      1.000     1.000     1.000         3\n",
      "              B-airline_code      1.000     0.963     0.981        27\n",
      "              B-airline_name      1.000     0.993     0.996       139\n",
      "              I-airline_name      1.000     0.975     0.987        80\n",
      "              B-airport_code      0.800     0.800     0.800         5\n",
      "              B-airport_name      0.500     0.429     0.462         7\n",
      "              I-airport_name      0.667     0.444     0.533         9\n",
      " B-arrive_date.date_relative      0.000     0.000     0.000         1\n",
      "      B-arrive_date.day_name      0.250     0.071     0.111        14\n",
      "    B-arrive_date.day_number      0.600     0.353     0.444        17\n",
      "    I-arrive_date.day_number      0.000     0.000     0.000         2\n",
      "    B-arrive_date.month_name      0.600     0.353     0.444        17\n",
      "      B-arrive_time.end_time      1.000     0.571     0.727         7\n",
      "      I-arrive_time.end_time      1.000     0.667     0.800         6\n",
      "    B-arrive_time.period_mod      0.000     0.000     0.000         1\n",
      " B-arrive_time.period_of_day      1.000     0.111     0.200         9\n",
      " I-arrive_time.period_of_day      0.000     0.000     0.000         0\n",
      "    B-arrive_time.start_time      1.000     0.571     0.727         7\n",
      "    I-arrive_time.start_time      1.000     1.000     1.000         3\n",
      "          B-arrive_time.time      0.821     0.744     0.780        43\n",
      "          I-arrive_time.time      0.811     0.857     0.833        35\n",
      " B-arrive_time.time_relative      0.829     0.784     0.806        37\n",
      "                 B-city_name      0.692     0.419     0.522        43\n",
      "                 I-city_name      0.400     0.571     0.471         7\n",
      "                B-class_type      0.979     0.979     0.979        47\n",
      "                I-class_type      1.000     1.000     1.000        38\n",
      "                   B-connect      0.889     0.889     0.889         9\n",
      "             B-cost_relative      1.000     1.000     1.000        60\n",
      "             I-cost_relative      0.800     1.000     0.889         4\n",
      "                  B-day_name      0.000     0.000     0.000         0\n",
      "                B-day_number      0.000     0.000     0.000         0\n",
      "                 B-days_code      0.000     0.000     0.000         0\n",
      " B-depart_date.date_relative      0.786     0.846     0.815        13\n",
      "      B-depart_date.day_name      0.919     0.981     0.949       161\n",
      "    B-depart_date.day_number      0.867     0.951     0.907        82\n",
      "    I-depart_date.day_number      0.880     0.957     0.917        23\n",
      "    B-depart_date.month_name      0.857     0.960     0.906        75\n",
      "B-depart_date.today_relative      0.920     1.000     0.958        23\n",
      "I-depart_date.today_relative      0.000     0.000     0.000         0\n",
      "          B-depart_date.year      1.000     1.000     1.000         8\n",
      "      B-depart_time.end_time      0.400     1.000     0.571         2\n",
      "      I-depart_time.end_time      0.333     1.000     0.500         1\n",
      "    B-depart_time.period_mod      0.867     0.929     0.897        14\n",
      " B-depart_time.period_of_day      0.929     0.956     0.942       136\n",
      " I-depart_time.period_of_day      0.000     0.000     0.000         0\n",
      "    B-depart_time.start_time      0.400     1.000     0.571         2\n",
      "    I-depart_time.start_time      1.000     1.000     1.000         1\n",
      "          B-depart_time.time      0.838     0.905     0.870        74\n",
      "          I-depart_time.time      0.907     0.875     0.891        56\n",
      " B-depart_time.time_relative      0.859     0.902     0.880        61\n",
      " I-depart_time.time_relative      0.000     0.000     0.000         0\n",
      "                   B-economy      1.000     1.000     1.000         9\n",
      "                   I-economy      1.000     1.000     1.000         2\n",
      "               B-fare_amount      0.833     1.000     0.909         5\n",
      "               I-fare_amount      1.000     1.000     1.000         5\n",
      "           B-fare_basis_code      1.000     0.938     0.968        16\n",
      "           I-fare_basis_code      0.000     0.000     0.000         0\n",
      "               B-flight_days      1.000     1.000     1.000         4\n",
      "                B-flight_mod      0.971     0.943     0.957        70\n",
      "                I-flight_mod      0.000     0.000     0.000         2\n",
      "             B-flight_number      1.000     0.905     0.950        21\n",
      "               B-flight_stop      0.972     0.921     0.946        38\n",
      "               I-flight_stop      1.000     0.333     0.500         6\n",
      "               B-flight_time      0.909     0.833     0.870        12\n",
      "               I-flight_time      0.833     0.833     0.833         6\n",
      "      B-fromloc.airport_code      1.000     0.800     0.889         5\n",
      "      B-fromloc.airport_name      0.842     0.800     0.821        20\n",
      "      I-fromloc.airport_name      0.909     0.690     0.784        29\n",
      "         B-fromloc.city_name      0.987     0.984     0.986       868\n",
      "         I-fromloc.city_name      0.971     1.000     0.985       134\n",
      "        B-fromloc.state_code      1.000     0.929     0.963        14\n",
      "        B-fromloc.state_name      1.000     1.000     1.000        12\n",
      "        I-fromloc.state_name      1.000     1.000     1.000         3\n",
      "                      B-meal      1.000     1.000     1.000        11\n",
      "                 B-meal_code      0.000     0.000     0.000         0\n",
      "                 I-meal_code      0.000     0.000     0.000         0\n",
      "          B-meal_description      1.000     1.000     1.000        12\n",
      "          I-meal_description      0.000     0.000     0.000         0\n",
      "                       B-mod      0.400     1.000     0.571         2\n",
      "                B-month_name      0.000     0.000     0.000         0\n",
      "                        B-or      1.000     0.950     0.974        20\n",
      "             B-period_of_day      0.000     0.000     0.000         0\n",
      "          B-restriction_code      1.000     0.667     0.800         6\n",
      "          I-restriction_code      1.000     1.000     1.000         1\n",
      " B-return_date.date_relative      0.500     0.500     0.500         2\n",
      " I-return_date.date_relative      0.000     0.000     0.000         0\n",
      "      B-return_date.day_name      0.000     0.000     0.000         0\n",
      "    B-return_date.day_number      0.000     0.000     0.000         1\n",
      "    B-return_date.month_name      0.000     0.000     0.000         1\n",
      "B-return_date.today_relative      0.000     0.000     0.000         0\n",
      "I-return_date.today_relative      0.000     0.000     0.000         0\n",
      "    B-return_time.period_mod      1.000     1.000     1.000         1\n",
      " B-return_time.period_of_day      1.000     0.500     0.667         2\n",
      "                B-round_trip      1.000     1.000     1.000        62\n",
      "                I-round_trip      1.000     1.000     1.000        61\n",
      "                B-state_code      0.333     1.000     0.500         1\n",
      "                B-state_name      0.000     0.000     0.000         0\n",
      "      B-stoploc.airport_name      0.000     0.000     0.000         0\n",
      "         B-stoploc.city_name      0.688     0.815     0.746        54\n",
      "         I-stoploc.city_name      1.000     0.500     0.667         6\n",
      "        B-stoploc.state_code      0.000     0.000     0.000         1\n",
      "                      B-time      0.000     0.000     0.000         0\n",
      "                      I-time      0.000     0.000     0.000         0\n",
      "             B-time_relative      0.000     0.000     0.000         0\n",
      "            B-today_relative      0.000     0.000     0.000         0\n",
      "            I-today_relative      0.000     0.000     0.000         0\n",
      "        B-toloc.airport_code      1.000     1.000     1.000         4\n",
      "        B-toloc.airport_name      0.750     0.818     0.783        11\n",
      "        I-toloc.airport_name      0.632     0.923     0.750        13\n",
      "           B-toloc.city_name      0.971     0.981     0.976       860\n",
      "           I-toloc.city_name      0.988     0.988     0.988       241\n",
      "        B-toloc.country_name      0.000     0.000     0.000         0\n",
      "          B-toloc.state_code      1.000     1.000     1.000        19\n",
      "          B-toloc.state_name      1.000     1.000     1.000        22\n",
      "          I-toloc.state_name      1.000     1.000     1.000         4\n",
      "            B-transport_type      1.000     0.778     0.875         9\n",
      "            I-transport_type      1.000     1.000     1.000         4\n",
      "\n",
      "                 avg / total      0.940     0.938     0.936      4121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise scores\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_valid, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a tagger object and open the trained file\n",
    "# tagger = pycrfsuite.Tagger()\n",
    "# tagger.open('atis.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what aircraft is used on delta flight DIGITDIGITDIGITDIGIT from kansas city to salt lake city\n"
     ]
    }
   ],
   "source": [
    "# tagging a sample sentence\n",
    "i = 0\n",
    "sample_sent = valid_labels[i]\n",
    "print(' '.join(sent2tokens(sample_sent)), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: O O O O O B-airline_name O B-flight_number O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name\n",
      "\n",
      "\n",
      "Correct:   O O O O O B-airline_name O B-flight_number O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name\n"
     ]
    }
   ],
   "source": [
    "# compare the predicted and actual labels for a query\n",
    "print(\"Predicted:\", ' '.join(y_pred[0]))\n",
    "print('\\n')\n",
    "print(\"Correct:  \", ' '.join(sent2labels(sample_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create (word, pos_tag, predicted_iob_label) tuples for a given dataset\n",
    "def append_predicted_tags(pos_tagged_data, labels):\n",
    "    iob_labels = []\n",
    "    for sent in list(zip(pos_tagged_data, labels)):\n",
    "        pos = sent[0]\n",
    "        labels = sent[1]\n",
    "        l = list(zip(pos, labels))\n",
    "        tuple_3 = [(i[0][0], i[0][1], i[1]) for i in l]\n",
    "        iob_labels.append(tuple_3)\n",
    "    return iob_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('aircraft', 'NN', 'O'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('used', 'VBN', 'O'),\n",
       " ('on', 'IN', 'O'),\n",
       " ('delta', 'JJ', 'B-airline_name'),\n",
       " ('flight', 'NN', 'O'),\n",
       " ('DIGITDIGITDIGITDIGIT', 'NNP', 'B-flight_number'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('kansas', 'NNP', 'B-fromloc.city_name'),\n",
       " ('city', 'NN', 'I-fromloc.city_name'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('salt', 'VB', 'B-toloc.city_name'),\n",
       " ('lake', 'JJ', 'I-toloc.city_name'),\n",
       " ('city', 'NN', 'I-toloc.city_name')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions of IOB tags on a sample validation query \n",
    "valid_tags = append_predicted_tags(valid_pos, y_pred)\n",
    "valid_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  what/WP\n",
      "  aircraft/NN\n",
      "  is/VBZ\n",
      "  used/VBN\n",
      "  on/IN\n",
      "  (airline_name delta/JJ)\n",
      "  flight/NN\n",
      "  (flight_number DIGITDIGITDIGITDIGIT/NNP)\n",
      "  from/IN\n",
      "  (fromloc.city_name kansas/NNP city/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name salt/VB lake/JJ city/NN))\n"
     ]
    }
   ],
   "source": [
    "# create a tree using the assigned iob labels\n",
    "valid_trees = [conlltags2tree(sent) for sent in valid_tags]\n",
    "print(valid_trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing a Chunked Tree\n",
    "\n",
    "Now that we have labelled (chunked) the validation and test datasets, let's see how we can traverse the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show me all flights from baltimore or denver or pittsburgh that fly to philadelphia \n",
      "\n",
      "fromloc.city_name [('baltimore', 'NN')]\n",
      "or [('or', 'CC')]\n",
      "fromloc.city_name [('denver', 'NN')]\n",
      "or [('or', 'CC')]\n",
      "fromloc.city_name [('pittsburgh', 'NN')]\n",
      "toloc.city_name [('philadelphia', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "i = random.randrange(len(valid_trees))\n",
    "i=771\n",
    "chunked_tree = valid_trees[i]\n",
    "\n",
    "print(' '.join([id_to_words[val] for val in val_x[i]]), '\\n')\n",
    "\n",
    "# traverse the tree and print labels of subtrees \n",
    "for n in chunked_tree:\n",
    "    if isinstance(n, nltk.tree.Tree):\n",
    "        print(n.label(), n.leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly parsed complex queries - i= 771, 25, 473, 23, 498, 893, 882, 694\n",
    "# ambiguous queries: not many so far\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all labels of train and validation trees\n",
    "tree_labels = []\n",
    "for tree in train_trees:\n",
    "    for n in tree:\n",
    "        if isinstance(n, nltk.tree.Tree):\n",
    "            tree_labels.append(n.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set has 78 unique labels\n",
    "label_set = set(tree_labels)\n",
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depart_time.time_relative',\n",
       " 'fromloc.state_name',\n",
       " 'return_time.period_of_day',\n",
       " 'fare_amount',\n",
       " 'depart_date.month_name',\n",
       " 'return_date.date_relative',\n",
       " 'fromloc.city_name',\n",
       " 'depart_time.time',\n",
       " 'class_type',\n",
       " 'meal_description']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first few labels\n",
    "list(label_set)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the CRF Classifier\n",
    "\n",
    "Let's now try to understand what the classifier has learnt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-fromloc.airport_name -> I-fromloc.airport_name 6.139828\n",
      "B-airport_name -> I-airport_name 6.040046\n",
      "B-depart_date.month_name -> B-depart_date.day_number 5.786839\n",
      "B-airline_name -> I-airline_name 5.694494\n",
      "B-arrive_date.month_name -> B-arrive_date.day_number 5.679481\n",
      "B-city_name -> I-city_name 5.639162\n",
      "B-toloc.airport_name -> I-toloc.airport_name 5.543314\n",
      "B-fromloc.city_name -> I-fromloc.city_name 5.271730\n",
      "B-flight_time -> I-flight_time 5.235649\n",
      "B-stoploc.city_name -> I-stoploc.city_name 5.072771\n",
      "B-toloc.city_name -> I-toloc.city_name 4.924069\n",
      "I-fromloc.airport_name -> I-fromloc.airport_name 4.912550\n",
      "I-depart_date.today_relative -> I-depart_date.today_relative 4.905395\n",
      "B-depart_time.time_relative -> B-depart_time.time 4.724515\n",
      "B-depart_date.day_number -> I-depart_date.day_number 4.704134\n",
      "B-depart_time.time -> I-depart_time.time 4.514564\n",
      "B-depart_time.end_time -> I-depart_time.end_time 4.491012\n",
      "I-flight_time -> I-flight_time 4.480120\n",
      "B-arrive_time.end_time -> I-arrive_time.end_time 4.478821\n",
      "I-city_name -> I-city_name 4.478231\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-arrive_date.date_relative -> B-depart_date.day_name -1.387490\n",
      "B-depart_date.day_name -> B-arrive_date.month_name -1.397373\n",
      "O      -> B-or    -1.403786\n",
      "B-depart_date.day_name -> B-arrive_time.period_of_day -1.416080\n",
      "O      -> I-depart_date.today_relative -1.417489\n",
      "B-toloc.city_name -> I-fromloc.city_name -1.475582\n",
      "B-toloc.city_name -> B-or    -1.537920\n",
      "B-depart_time.time_relative -> B-arrive_time.time -1.604171\n",
      "O      -> I-fromloc.airport_name -1.640295\n",
      "I-arrive_time.time -> B-depart_date.date_relative -1.685604\n",
      "B-toloc.city_name -> I-toloc.airport_name -1.695908\n",
      "B-arrive_time.time -> I-depart_time.time -1.743275\n",
      "O      -> I-city_name -1.802009\n",
      "O      -> I-toloc.city_name -1.802546\n",
      "B-arrive_date.day_name -> B-depart_time.period_of_day -1.824814\n",
      "B-depart_time.time -> I-arrive_time.time -1.910633\n",
      "B-arrive_time.time_relative -> B-depart_time.time -2.051462\n",
      "B-depart_date.day_name -> B-arrive_time.time_relative -2.068858\n",
      "O      -> I-flight_time -2.250896\n",
      "O      -> I-airline_name -2.659119\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.297233 B-fromloc.city_name prevword:from\n",
      "5.104957 B-arrive_time.time_relative prevword:arriving\n",
      "5.059366 B-arrive_time.time_relative prevword:arrive\n",
      "4.949039 B-toloc.state_name word_is_state\n",
      "4.017096 B-depart_time.start_time prevword:between\n",
      "3.841796 B-stoploc.city_name prevword:through\n",
      "3.826135 B-fromloc.city_name prevword:leaving\n",
      "3.819081 O        pos:DT\n",
      "3.725986 I-depart_date.day_number prevword:twenty\n",
      "3.703128 B-toloc.city_name prevword:into\n",
      "3.588173 B-arrive_time.start_time prevword:between\n",
      "3.566806 B-fromloc.airport_name prevword:from\n",
      "3.506935 B-fromloc.city_name prevword:between\n",
      "3.481669 B-fromloc.city_name prevword:leave\n",
      "3.457800 B-stoploc.city_name prevword:via\n",
      "3.419583 B-toloc.city_name prevword:for\n",
      "3.369874 B-flight_number prevword:flight\n",
      "3.310759 B-toloc.city_name prevword:downtown\n",
      "3.298952 B-city_name prevword:serve\n",
      "3.286938 B-toloc.city_name prevword:arriving\n",
      "3.281605 B-flight_mod nextword:flight\n",
      "3.273857 O        suff_1:e\n",
      "3.221108 B-fromloc.city_name prevword:depart\n",
      "3.153781 B-toloc.city_name word_is_city\n",
      "3.145663 O        prevword:dinnertime\n",
      "3.141976 B-class_type nextword:class\n",
      "3.116168 B-fromloc.city_name word_is_city\n",
      "3.101636 B-return_date.date_relative prevword:same\n",
      "3.092508 B-mod    nextword:seating\n",
      "3.056442 B-fromloc.state_name word_is_state\n",
      "\n",
      "Top negative:\n",
      "-1.303362 B-fromloc.city_name prevword:for\n",
      "-1.314199 B-arrive_time.time_relative prevword:francisco\n",
      "-1.316259 B-depart_date.day_number nextword:with\n",
      "-1.325397 B-depart_time.time_relative prevword:monday\n",
      "-1.326700 B-toloc.city_name nextword:to\n",
      "-1.326700 B-toloc.city_name nextpos:TO\n",
      "-1.343932 I-fromloc.city_name word_is_state\n",
      "-1.348694 O        suff_2:al\n",
      "-1.384626 B-flight_stop nextpos:IN\n",
      "-1.389035 I-toloc.city_name nextword:for\n",
      "-1.401758 B-toloc.city_name prevpos:VBZ\n",
      "-1.415015 O        nextword:seating\n",
      "-1.431632 B-depart_time.time_relative prevword:newark\n",
      "-1.467101 B-toloc.city_name prevpos:NN\n",
      "-1.485325 O        prevword:on\n",
      "-1.499093 O        suff_3:day\n",
      "-1.553078 B-depart_date.day_name word_is_city\n",
      "-1.605193 B-toloc.city_name prevword:leave\n",
      "-1.652399 O        suff_4:ning\n",
      "-1.709932 B-depart_time.period_of_day prevword:late\n",
      "-1.723074 O        prevword:fly\n",
      "-1.812572 O        suff_2:st\n",
      "-1.905599 O        nextword:day\n",
      "-1.935902 B-fromloc.city_name prevword:at\n",
      "-2.060522 B-arrive_time.time_relative prevpos:VB\n",
      "-2.074255 B-fromloc.city_name prevword:flights\n",
      "-2.221668 O        nextword:than\n",
      "-2.266080 O        prevword:code\n",
      "-2.980735 O        prevword:returning\n",
      "-3.098574 O        word_is_city\n"
     ]
    }
   ],
   "source": [
    "# important features\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlightStats API Experiments\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flightstats API experiments\n",
    "app_id = '9bed5b33'\n",
    "app_key = 'd7a448569ce9d0821da4fcc9f371e8cc'\n",
    "\n",
    "base_url = 'https://api.flightstats.com/flex/schedules/rest/v1/json/from/'\n",
    "\n",
    "# {departureAirportCode}/to/{arrivalAirportCode}/departing/{year}/{month}/{day}\n",
    "# departing from ABQ to DFW on 20 Dec 2018\n",
    "extended_url = 'ABQ/to/DFW/departing/2018/12/20'\n",
    "\n",
    "# credentials\n",
    "creds = '?appId={0}&appKey={1}'.format(app_id, app_key)\n",
    "\n",
    "# complete url\n",
    "url = base_url + extended_url + creds\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "data = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample flight details\n",
    "data['scheduledFlights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.flightstats.com/api-docs/scheduledFlights/v1\n",
    "# https://developer.flightstats.com/api-docs/\n",
    "# https://developer.flightstats.com/api-docs/how_to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
