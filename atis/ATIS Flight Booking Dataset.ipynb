{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATIS Flight Reservations Dataset\n",
    "\n",
    "Dataset download link: http://lisaweb.iro.umontreal.ca/transfert/lisa/users/mesnilgr/atis/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, pprint, os\n",
    "import gzip, os, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the first part of the dataset\n",
    "# each part (.gz file) contains train, validation and test sets, plus a dict\n",
    "\n",
    "filename = 'atis.fold0.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "try:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')\n",
    "except:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f)\n",
    "finally:\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3983)"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3983)\n",
      "(3, 995)\n",
      "(3, 893)\n"
     ]
    }
   ],
   "source": [
    "# structure of the component data files\n",
    "print(np.shape(train_set))\n",
    "print(np.shape(valid_set))\n",
    "print(np.shape(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<class 'list'>\n",
      "3983\n"
     ]
    }
   ],
   "source": [
    "# each set is a 3-tuple, each element of the tuple being a list \n",
    "print(len(train_set))\n",
    "print(type(train_set[0]))\n",
    "print(len(train_set[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list has 3983 arrays, each array being a sentence. The words are encoded by numbers (and have to be decoded using the dict provided).\n",
    "\n",
    "Let's store the three lists into separate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the three elements of the tuple in three objects\n",
    "train_x, _, train_label = train_set\n",
    "val_x, _, val_label = valid_set\n",
    "test_x, _, test_label = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list represents the actual words (encoded), and the third list contains their labels (again, encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([554, 194, 268,  64,  62,  16,   8, 234, 481,  20,  40,  58, 234,\n",
       "       415, 205])"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each list in the tuple is a numpy array (a sentence)\n",
    "# printing first list in the tuple's first element\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 126, 126,  48, 126,  36,  35, 126, 126,  33, 126, 126, 126,\n",
       "        78, 123])"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels are stored in the third list train_label\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['labels2idx', 'tables2idx', 'words2idx'])\n"
     ]
    }
   ],
   "source": [
    "# dicts \n",
    "print(type(dicts))\n",
    "print(dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# each key:value pair is itself a dict\n",
    "print(type(dicts['labels2idx']))\n",
    "print(type(dicts['tables2idx']))\n",
    "print(type(dicts['words2idx']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing labels and words in separate variables\n",
    "words = dicts['words2idx']\n",
    "labels = dicts['labels2idx']\n",
    "tables = dicts['tables2idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all', 'coach', 'cincinnati', 'people', 'month', 'four', 'code', 'go', 'show', 'thursday', 'to', 'restriction', 'dinnertime', 'under', 'sorry', 'include', 'midwest', 'worth', 'southwest', 'me', 'returning', 'far', 'vegas', 'airfare', 'ticket', 'difference', 'arrange', 'tickets', 'louis', 'cheapest', 'list', 'wednesday', 'leave', 'heading', 'ten', 'direct', 'turboprop', 'rate', 'cost', 'quebec', 'layover', 'air', 'what', 'stands', 'chicago', 'schedule', 'transcontinental', 'goes', 'new', 'transportation', 'here', 'hours', 'let', 'twentieth', 'along', 'thrift', 'passengers', 'great', 'thirty', 'canadian', 'leaves', 'alaska', 'leaving', 'amount', 'weekday', 'makes', 'midway', 'montreal', 'via', 'depart', 'county', 'names', 'stand', 'total', 'seventeenth', 'use', 'twa', 'from', 'would', 'abbreviations', 'destination', 'only', 'next', 'live', 'shortest', 'limousine', 'tell', 'today', 'more', 'DIGIT', 'm80', 'downtown', 'train', 'tampa', 'fly', 'f', 'this', 'car', 'anywhere', 'can', 'following', 'making', 'arrive', 'my', 'could', 'give', 'december', 'numbers', 'want', 'DIGITDIGITDIGITDIGITDIGITDIGIT', 'airplane', 'times', 'information', 'tacoma', 'provide', 'travel', 'six', 'dinner', 'located', 'sunday', 'fourth', 'types', 'beach', 'nonstop', 'economy', 'fare', 'okay', 'y', 'may', 'earlier', 'plane', 'ff', 'coming', 'eighth', 'fn', 'las', 'a', 'boeing', 'third', 'departure', 'q', 'so', 'rentals', 'houston', 'serving', 'help', 'september', 'over', 'midnight', 'soon', 'logan', 'through', 'milwaukee', 'still', 'before', 'thirtieth', 'thank', 'fit', 'how', 'trying', 'denver', 'actually', 'late', 'offers', 'listing', 'texas', 'DIGITDIGITDIGITDIGIT', 'then', 'evening', 'return', 'yn', 'lunch', 'wednesdays', 'they', 'arriving', 'now', 'rental', 'day', 'landings', 'february', 'airports', 'name', 'sundays', 'january', 'detroit', 'each', 'meal', 'dulles', 'petersburg', 'thirteenth', 'ea', 'used', 'arrives', 'connect', 'requesting', 'tenth', 'saturday', 'out', 'canada', 'looking', 'arizona', 'cars', 'friday', 'seventh', 'california', 'york', 'bwi', 'ord', 'earliest', 'repeat', 'dc10', 'atl', 'florida', 'days', 'round', 'american', 'afternoon', 'st.', 'first', 'there', 'number', 'one', 'eleventh', 'approximately', 'another', 'tomorrow', '<UNK>', 'city', 'service', 'twenty', 'dfw', 'weekdays', 'least', 'their', 'rates', 'DIGITDIGITDIGIT', 'time', 'too', 'sixteenth', 'that', 'pittsburgh', 'serve', 'july', 'than', 'toronto', 'distance', 'kind', 'b', 'second', 'pennsylvania', 'classes', 'other', 'traveling', 'and', 'charlotte', 'san', 'stopovers', 'boston', 'takeoff', 'say', 'buy', 'rent', 'have', 'need', 'breakfast', 'philly', 'any', 'sa', 'dallas', 'also', 'without', 'take', 'which', 'sure', 'price', 'who', 'serviced', 'most', 'eight', 'landing', 'services', 'america', 'class', 'later', 'm', 'nineteenth', 'salt', 'departing', 'cheap', 'tuesdays', 'find', 'fifth', 'ground', 'snack', 'with', 'explain', 'minnesota', 'should', 'flights', 'going', 'qx', 'carolina', 'do', 'dl', 'get', 'michigan', 'express', 'stop', 'dc', 'international', 'during', 'westchester', 'qw', 'stapleton', 'h', 'morning', 'wish', 'ohio', 'where', 'qo', 'arrival', 'eighteenth', 'up', 'connections', 'see', 'are', 'close', 'yes', 'capacity', 'please', 'smallest', 'various', 'between', 'f28', 'available', 'we', 'august', 's', 'nashville', 'aircraft', 'fifteenth', 'cities', 'jfk', 'both', 'c', 'last', 'many', 'taking', 'la', 'trips', 'april', 'connection', 'baltimore', 'flies', 'co', 'tuesday', 'nonstops', 'tennessee', 'stopover', 'cp', 'november', 'expensive', 'west', 'airlines', 'nationair', 'much', 'define', 'mco', 'flight', 'eastern', 'airplanes', 'lives', 'prices', 'atlanta', 'an', 'those', 'sfo', 'georgia', 'look', 'these', 'originate', 'choices', 'will', 'near', 'itinerary', 'stopping', 'mitchell', 'fourteenth', 'thursdays', 'is', 'it', 'arrangements', 'in', 'seattle', 'if', 'different', 'make', 'airport', 'same', 'northwest', 'ewr', 'twelfth', 'week', 'indianapolis', 'diego', 'takeoffs', 'uses', 'two', 'database', 'i', 'well', 'options', 'costs', 'jersey', 'very', 'the', 'latest', 'taxi', 'just', 'less', 'ninth', 'abbreviation', 'seats', 'love', 'paul', 'jose', 'sixteen', 'lake', 'book', 'ap80', 'fares', 'has', 'march', 'around', 'utah', 'possible', 'early', 'know', 'schedules', 'using', 'like', 'd', 'miami', 'orlando', 'arrivals', 'either', 'night', 'served', 'tower', 'limo', 'seating', 'right', 'saturdays', 'lastest', 'some', 'back', \"'t\", 'serves', 'cleveland', \"'s\", 'transport', 'provided', 'oakland', 'phoenix', 'for', 'noon', 'stops', 'newark', 'does', 'connecting', 'booking', 'be', 'columbus', 'business', 'reaching', 'sixth', 'departures', 'ap57', 'by', 'after', 'on', 'about', 'noontime', 'DIGITDIGIT', 'of', 'dollars', 'burbank', 'angeles', 'carries', 'airline', 'mean', 'or', 'plan', 'colorado', 'united', 'into', 'within', 'washington', 'bound', 'three', 'your', 'guardia', 'ontario', 'area', 'flying', 'philadelphia', 'long', 'continental', 'los', '72s', 'way', 'lowest', 'mornings', 'north', 'offer', 'hp', 'restrictions', 'but', 'hi', 'delta', 'highest', 'memphis', 'fort', 'october', 'type', 'maximum', 'us', \"'re\", 'planes', 'pm', 'ua', 'display', 'originating', 'ac', 'reservations', 'describe', 'am', 'minneapolis', 'general', 'ap', 'as', 'sometime', 'at', 'trip', 'again', 'codes', \"'ll\", 'no', 'when', 'field', 'interested', 'you', 'nw', 'francisco', 'kinds', 'monday', \"o'clock\", 'kansas', 'june', 'lufthansa', 'meaning', \"'d\", 'reservation', \"'m\", 'friends', 'meals', 'land', 'daily', 'departs', 'missouri', 'starting', 'hello'])"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each key of words_dict is a word, each value its index\n",
    "words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'flights',\n",
       " 'leave',\n",
       " 'atlanta',\n",
       " 'at',\n",
       " 'about',\n",
       " 'DIGIT',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'and',\n",
       " 'arrive',\n",
       " 'in',\n",
       " 'san',\n",
       " 'francisco']"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we can map the numeric values v in a sentence with the k,v in the dict\n",
    "# train_x contains the list of training sentences\n",
    "# this is the first sentence\n",
    "[k for val in train_x[0] for k,v in words.items() if v==val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco',\n",
       " 'what is the abbreviation for canadian airlines international',\n",
       " \"i 'd like to know the earliest flight from boston to atlanta\",\n",
       " 'show me the us air flights from atlanta to boston',\n",
       " 'show me the cheapest round trips from dallas to baltimore',\n",
       " \"i 'd like to see all flights from denver to philadelphia\",\n",
       " 'explain fare code qx',\n",
       " \"i 'd like a united airlines flight on wednesday from san francisco to boston\",\n",
       " 'what is the price of american airlines flight DIGITDIGIT from new york to los angeles',\n",
       " 'what does the meal code s stand for',\n",
       " 'what are all flights to denver from philadelphia on sunday',\n",
       " 'what times does the late afternoon flight leave from washington for denver',\n",
       " 'what flights are available monday from san francisco to pittsburgh',\n",
       " 'what airlines have business class',\n",
       " 'flights from atlanta to washington dc',\n",
       " 'from new york to toronto on thursday morning',\n",
       " 'show me all the direct flights from atlanta to baltimore',\n",
       " 'list the flights from new york to miami on a tuesday which are nonstop and cost less than DIGITDIGITDIGIT dollars',\n",
       " 'show me the first flight that arrives in toronto from cincinnati',\n",
       " 'what planes are used by twa',\n",
       " 'please give me the prices for all flights from philadelphia to denver airport next sunday',\n",
       " 'show me all flights from pittsburgh to oakland that arrive after DIGITDIGIT am',\n",
       " 'what is the least expensive flight today from atlanta to san francisco',\n",
       " 'i want a flight from philadelphia to dallas with a stop in atlanta',\n",
       " 'show me the flights from baltimore to philadelphia',\n",
       " 'what airlines fly from st. petersburg to milwaukee and from milwaukee to tacoma',\n",
       " 'please give me the flights from san francisco to washington dc',\n",
       " 'i need a flight delta airlines kansas city to salt lake',\n",
       " 'show me flights going from boston to denver arriving on wednesday morning',\n",
       " 'show me flights leaving from denver colorado to pittsburgh pennsylvania on wednesdays after DIGIT pm']"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the first few sentences\n",
    "sents = []\n",
    "for i in range(30):\n",
    "    sents.append(' '.join([k for val in train_x[i] for k,v in words.items() if v==val]))\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['B-time_relative', 'B-stoploc.state_code', 'B-depart_date.today_relative', 'B-arrive_date.date_relative', 'B-depart_date.date_relative', 'I-restriction_code', 'B-return_date.month_name', 'I-time', 'B-depart_date.day_name', 'I-arrive_time.end_time', 'B-fromloc.airport_code', 'B-cost_relative', 'B-connect', 'B-return_time.period_mod', 'B-arrive_time.period_mod', 'B-flight_number', 'B-depart_time.time_relative', 'I-toloc.city_name', 'B-arrive_time.period_of_day', 'B-depart_time.period_of_day', 'I-return_date.date_relative', 'I-depart_time.start_time', 'B-fare_amount', 'I-depart_time.time_relative', 'B-city_name', 'B-depart_date.day_number', 'I-meal_description', 'I-depart_date.today_relative', 'I-airport_name', 'I-arrive_date.day_number', 'B-toloc.state_code', 'B-arrive_date.month_name', 'B-stoploc.airport_code', 'I-depart_time.time', 'B-airport_code', 'B-arrive_time.start_time', 'B-period_of_day', 'B-arrive_time.time', 'I-flight_stop', 'B-toloc.state_name', 'B-booking_class', 'I-meal_code', 'B-arrive_time.end_time', 'B-meal', 'B-arrive_time.time_relative', 'B-return_date.day_number', 'I-city_name', 'B-day_name', 'B-or', 'I-flight_mod', 'I-arrive_time.time', 'B-economy', 'B-fromloc.airport_name', 'B-return_date.day_name', 'O', 'B-class_type', 'B-meal_code', 'B-depart_time.time', 'B-return_date.today_relative', 'B-round_trip', 'B-restriction_code', 'B-fare_basis_code', 'I-stoploc.city_name', 'I-fare_basis_code', 'B-flight', 'I-fromloc.airport_name', 'B-compartment', 'B-airline_code', 'B-fromloc.state_name', 'B-flight_stop', 'B-day_number', 'B-flight_mod', 'I-arrive_time.period_of_day', 'B-depart_time.start_time', 'B-today_relative', 'I-arrive_time.time_relative', 'B-arrive_date.day_number', 'I-flight_time', 'B-arrive_date.day_name', 'I-fromloc.state_name', 'B-mod', 'B-depart_date.month_name', 'B-flight_days', 'I-cost_relative', 'B-stoploc.airport_name', 'I-today_relative', 'B-fromloc.city_name', 'B-transport_type', 'B-return_time.period_of_day', 'B-time', 'B-toloc.country_name', 'B-return_date.date_relative', 'I-depart_date.day_number', 'I-transport_type', 'I-fromloc.city_name', 'B-depart_date.year', 'I-return_date.day_number', 'B-flight_time', 'B-toloc.city_name', 'B-depart_time.period_mod', 'I-arrive_time.start_time', 'B-state_code', 'B-airport_name', 'B-stoploc.city_name', 'I-toloc.airport_name', 'B-meal_description', 'I-class_type', 'B-toloc.airport_code', 'I-depart_time.period_of_day', 'I-toloc.state_name', 'B-days_code', 'B-toloc.airport_name', 'B-arrive_date.today_relative', 'I-round_trip', 'I-state_name', 'I-fare_amount', 'B-airline_name', 'I-flight_number', 'I-airline_name', 'B-state_name', 'I-economy', 'B-depart_time.end_time', 'B-aircraft_code', 'I-return_date.today_relative', 'B-month_name', 'B-fromloc.state_code', 'I-depart_time.end_time'])"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels dict contains IOB (inside-out-beginning) labelled entities\n",
    "labels.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 127 classes of labels (including the 'O' - tokens that do not fall into any entity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "# number of labels\n",
    "print(len(labels.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dicts 'words' and 'labels' are key:value pairs of index:word/label, let's reverse the dicts so that we don't have to do a reverse lookup everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting words_to_id to id_to_words\n",
    "# and labels_to_id to id_to_labels\n",
    "id_to_words = {words[k]:k for k in words}\n",
    "id_to_labels = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the words and corresponding labels simply by looking up the value of a numeric index of each word, for e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tell', 'O'), ('me', 'O'), ('about', 'O'), ('ground', 'O'), ('transportation', 'O'), ('between', 'O'), ('orlando', 'B-fromloc.airport_name'), ('international', 'I-fromloc.airport_name'), ('and', 'O'), ('orlando', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('how', 'O'), ('about', 'O'), ('flights', 'O'), ('leaving', 'O'), ('san', 'B-fromloc.city_name'), ('francisco', 'I-fromloc.city_name'), ('and', 'O'), ('arriving', 'O'), ('in', 'O'), ('boston', 'B-toloc.city_name'), ('for', 'O'), ('any', 'O'), ('day', 'O')]\n",
      "\n",
      "\n",
      "[('round', 'B-round_trip'), ('trip', 'I-round_trip'), ('air', 'O'), ('fares', 'O'), ('from', 'O'), ('baltimore', 'B-fromloc.city_name'), ('to', 'O'), ('philadelphia', 'B-toloc.city_name'), ('less', 'B-cost_relative'), ('than', 'O'), ('DIGITDIGITDIGITDIGIT', 'B-fare_amount'), ('dollars', 'I-fare_amount')]\n",
      "\n",
      "\n",
      "[('please', 'O'), ('give', 'O'), ('me', 'O'), ('the', 'O'), ('united', 'B-airline_name'), ('airlines', 'I-airline_name'), ('flights', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('baltimore', 'B-toloc.city_name'), ('that', 'O'), ('are', 'O'), ('the', 'O'), ('first', 'B-class_type'), ('class', 'I-class_type'), ('flights', 'O'), ('please', 'O')]\n",
      "\n",
      "\n",
      "[('do', 'O'), ('you', 'O'), ('have', 'O'), ('the', 'O'), ('fare', 'O'), ('for', 'O'), ('traveling', 'O'), ('from', 'O'), ('oakland', 'B-fromloc.airport_name'), ('airport', 'I-fromloc.airport_name'), ('to', 'O'), ('oakland', 'B-toloc.city_name'), ('downtown', 'O')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('to', 'O'), ('see', 'O'), ('all', 'O'), ('flights', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('philadelphia', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('okay', 'O'), ('on', 'O'), ('monday', 'B-depart_date.day_name'), ('may', 'B-depart_date.month_name'), ('thirty', 'B-depart_date.day_number'), ('first', 'I-depart_date.day_number'), ('i', 'O'), (\"'d\", 'O'), ('like', 'O'), ('to', 'O'), ('go', 'O'), ('from', 'O'), ('san', 'B-fromloc.city_name'), ('diego', 'I-fromloc.city_name'), ('to', 'O'), ('phoenix', 'B-toloc.city_name'), ('early', 'B-depart_time.period_mod'), ('in', 'O'), ('the', 'O'), ('morning', 'B-depart_time.period_of_day')]\n",
      "\n",
      "\n",
      "[('how', 'O'), ('far', 'O'), ('is', 'O'), ('downtown', 'O'), ('from', 'O'), ('the', 'O'), ('airport', 'O'), ('in', 'O'), ('dallas', 'B-fromloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('to', 'O'), ('travel', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('denver', 'B-toloc.city_name'), ('early', 'B-depart_time.period_mod'), ('in', 'O'), ('the', 'O'), ('morning', 'B-depart_time.period_of_day')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('one', 'O'), ('more', 'O'), ('time', 'O'), ('the', 'O'), ('first', 'B-class_type'), ('class', 'I-class_type'), ('fares', 'O'), ('from', 'O'), ('baltimore', 'B-fromloc.city_name'), ('to', 'O'), ('dallas', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('all', 'O'), ('nationair', 'B-airline_name'), ('flights', 'O'), ('from', 'O'), ('toronto', 'B-fromloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('a', 'O'), ('flight', 'O'), ('from', 'O'), ('atlanta', 'B-fromloc.city_name'), ('to', 'O'), ('denver', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('is', 'O'), ('the', 'O'), ('earliest', 'B-flight_mod'), ('flight', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('san', 'B-toloc.city_name'), ('francisco', 'I-toloc.city_name'), ('on', 'O'), ('american', 'B-airline_name'), ('airlines', 'I-airline_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), (\"'m\", 'O'), ('trying', 'O'), ('to', 'O'), ('fly', 'O'), ('from', 'O'), ('denver', 'B-fromloc.city_name'), ('to', 'O'), ('boston', 'B-toloc.city_name'), ('and', 'O'), ('i', 'O'), ('want', 'O'), ('a', 'O'), ('flight', 'O'), ('that', 'O'), ('serves', 'O'), ('a', 'O'), ('meal', 'B-meal')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('from', 'O'), ('minneapolis', 'B-fromloc.city_name'), ('to', 'O'), ('pittsburgh', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), (\"'s\", 'O'), ('the', 'O'), ('earliest', 'B-flight_mod'), ('flight', 'O'), ('from', 'O'), ('dallas', 'B-fromloc.city_name'), ('to', 'O'), ('houston', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('american', 'B-airline_name'), ('airlines', 'I-airline_name'), ('flights', 'O'), ('from', 'O'), ('phoenix', 'B-fromloc.city_name'), ('to', 'O'), ('milwaukee', 'B-toloc.city_name'), ('depart', 'O'), ('phoenix', 'B-fromloc.city_name'), ('after', 'B-depart_time.time_relative'), ('DIGIT', 'B-depart_time.time'), ('pm', 'I-depart_time.time'), ('on', 'O'), ('wednesday', 'B-depart_date.day_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('the', 'O'), ('flight', 'O'), ('number', 'O'), ('and', 'O'), ('the', 'O'), ('time', 'B-flight_time'), ('for', 'O'), ('the', 'O'), ('cheapest', 'B-cost_relative'), ('fare', 'O'), ('that', 'O'), ('is', 'O'), ('the', 'O'), ('least', 'B-cost_relative'), ('expensive', 'I-cost_relative'), ('first', 'B-class_type'), ('class', 'I-class_type'), ('fare', 'O'), ('from', 'O'), ('san', 'B-fromloc.city_name'), ('francisco', 'I-fromloc.city_name'), ('to', 'O'), ('pittsburgh', 'B-toloc.city_name'), ('leaving', 'O'), ('after', 'B-depart_time.time_relative'), ('DIGIT', 'B-depart_time.time'), ('pm', 'I-depart_time.time'), ('monday', 'B-depart_date.day_name'), ('night', 'B-depart_time.period_of_day')]\n",
      "\n",
      "\n",
      "[('list', 'O'), ('the', 'O'), ('first', 'B-class_type'), ('class', 'I-class_type'), ('flights', 'O'), ('from', 'O'), ('baltimore', 'B-fromloc.city_name'), ('to', 'O'), ('denver', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('are', 'O'), ('the', 'O'), ('flights', 'O'), ('between', 'O'), ('dallas', 'B-fromloc.city_name'), ('and', 'O'), ('pittsburgh', 'B-toloc.city_name'), ('on', 'O'), ('july', 'B-depart_date.month_name'), ('eight', 'B-depart_date.day_number')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing a few randomly chosen sentences and the corresponding labels (tagged entities)\n",
    "for i in random.sample(range(len(train_x)), 20):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[i]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[i]))\n",
    "    print(list(zip(w, l)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function which takes in an index and returns the corresponding query with its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query(index):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[index]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[index]))\n",
    "    s = list(zip(w, l))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('on', 'O'),\n",
       " ('<UNK>', 'B-airline_name'),\n",
       " ('air', 'I-airline_name'),\n",
       " ('how', 'O'),\n",
       " ('many', 'O'),\n",
       " ('flights', 'O'),\n",
       " ('leaving', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('july', 'B-depart_date.month_name'),\n",
       " ('twenty', 'B-depart_date.day_number'),\n",
       " ('seventh', 'I-depart_date.day_number'),\n",
       " ('to', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('nonstop', 'B-flight_stop')]"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3925)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some queries specify stopover cities, such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'O'),\n",
       " ('there', 'O'),\n",
       " ('a', 'O'),\n",
       " ('flight', 'O'),\n",
       " ('between', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('and', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('stopover', 'O'),\n",
       " ('in', 'O'),\n",
       " ('dallas', 'B-stoploc.city_name'),\n",
       " ('fort', 'I-stoploc.city_name'),\n",
       " ('worth', 'I-stoploc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('twa', 'B-airline_code')]"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this dataset, queries are far more complex (in terms of number of labels, variety in the sentence structures etc.) and thus we cannot  write simple hand-written rules to extract chunks such as to_from_city, types_of_meals etc. \n",
    "\n",
    "Thus, we need to train probabilistic models such as CRFs, HMMs etc. to tag each word with its corresponding entity label.\n",
    "\n",
    "We'll use the training and validation sets ```train_x``` and ```valid_x``` as to tune the model, and finaly use test set to measure the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for NER\n",
    "\n",
    "Let's experiment with a few different models for labelling words with named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging sentences\n",
    "# takes in a list of sentences and returns a list of POS-tagged sentences\n",
    "# in the form (word, tag)\n",
    "\n",
    "def pos_tag(sent_list):\n",
    "    pos_tags = []    \n",
    "    for sent in sent_list:\n",
    "        tagged_words = nltk.pos_tag([id_to_words[val] for val in sent])\n",
    "        pos_tags.append(tagged_words)\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagging train, validation and test sets\n",
    "train_pos = pos_tag(train_x)\n",
    "valid_pos = pos_tag(val_x)\n",
    "test_pos = pos_tag(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('find', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('latest', 'JJS'),\n",
       " ('return', 'NN'),\n",
       " ('flight', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('atlanta', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('boston', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('day', 'NN')]"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at tags of some randomly chosen queries\n",
    "# notice that most cities after 'TO' are tagged as VB\n",
    "i = random.randrange(len(train_pos))\n",
    "train_pos[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need the entity labels of each word along with the POS tags, for e.g. in this format:\n",
    "```[('New', 'NNP', u'B-GPE'), ('York', 'NNP', u'I-GPE'), ('is', 'VBZ', u'O'), ('my', 'PRP$', u'O'), ('favorite', 'JJ', u'O'), ('city', 'NN', u'O')]```\n",
    "\n",
    "Let's convert the training and validation sentences to this form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create (word, pos_tag, iob_label) tuples for a given dataset\n",
    "def create_word_pos_label(pos_tagged_data, labels):\n",
    "    iob_labels = []\n",
    "    for sent in list(zip(pos_tagged_data, labels)):\n",
    "        pos = sent[0]\n",
    "        labels = sent[1]\n",
    "        l = list(zip(pos, labels))\n",
    "        tuple_3 = [(i[0][0], i[0][1], id_to_labels[i[1]]) for i in l]\n",
    "        iob_labels.append(tuple_3)\n",
    "    return iob_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('what', 'WP', 'O'),\n",
       "  ('flights', 'NNS', 'O'),\n",
       "  ('leave', 'VBP', 'O'),\n",
       "  ('atlanta', 'VBN', 'B-fromloc.city_name'),\n",
       "  ('at', 'IN', 'O'),\n",
       "  ('about', 'RB', 'B-depart_time.time_relative'),\n",
       "  ('DIGIT', 'NNP', 'B-depart_time.time'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('afternoon', 'NN', 'B-depart_time.period_of_day'),\n",
       "  ('and', 'CC', 'O'),\n",
       "  ('arrive', 'NN', 'O'),\n",
       "  ('in', 'IN', 'O'),\n",
       "  ('san', 'JJ', 'B-toloc.city_name'),\n",
       "  ('francisco', 'NN', 'I-toloc.city_name')],\n",
       " [('what', 'WP', 'O'),\n",
       "  ('is', 'VBZ', 'O'),\n",
       "  ('the', 'DT', 'O'),\n",
       "  ('abbreviation', 'NN', 'O'),\n",
       "  ('for', 'IN', 'O'),\n",
       "  ('canadian', 'JJ', 'B-airline_name'),\n",
       "  ('airlines', 'NNS', 'I-airline_name'),\n",
       "  ('international', 'JJ', 'I-airline_name')]]"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = create_word_pos_label(train_pos, train_label)\n",
    "train_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('flights', 'NNS', 'O'),\n",
       " ('are', 'VBP', 'O'),\n",
       " ('there', 'RB', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('houston', 'NN', 'B-fromloc.city_name'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('dallas', 'VB', 'B-toloc.city_name')]"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some sample training sentences\n",
    "train_labels[random.randrange(len(train_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for validation and test data\n",
    "valid_labels = create_word_pos_label(valid_pos, val_label)\n",
    "test_labels = create_word_pos_label(test_pos, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Tree Format\n",
    "\n",
    "Let's now convert the sentences into a tree format, which is needed by NLTK to train taggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  i/JJ\n",
      "  'd/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  know/VB\n",
      "  the/DT\n",
      "  (flight_mod earliest/JJS)\n",
      "  flight/NN\n",
      "  from/IN\n",
      "  (fromloc.city_name boston/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name atlanta/VB))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "from nltk import conlltags2tree, tree2conlltags\n",
    "\n",
    "# converting a sample sentence to a tree\n",
    "tree = conlltags2tree(train_labels[2])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert all training sentences to trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training, validation and test datasets to tree format\n",
    "train_trees = [conlltags2tree(sent) for sent in train_labels]\n",
    "valid_trees = [conlltags2tree(sent) for sent in valid_labels]\n",
    "test_trees = [conlltags2tree(sent) for sent in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S what/WP does/VBZ (airport_code ewr/JJ) mean/VB)\n"
     ]
    }
   ],
   "source": [
    "# print some sample training trees\n",
    "print(train_trees[random.randrange(len(train_trees))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try building some parsers. \n",
    "\n",
    "### Regex Based Parsers\n",
    "\n",
    "Let's start with a dummy parser - one which tags every token as an 'O'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  63.6%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# a dummy chunk parser - tags every word as 'O'\n",
    "cp = nltk.RegexpParser(r'')\n",
    "print(cp.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tell us that about 63% of the tokens are tagged as 'O', i.e. they are not a named entity of any type. The precision, recall etc. are zero because we did not find any chunks at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Chunker\n",
    "\n",
    "Let's now try a unigram chunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram chunker\n",
    "\n",
    "from nltk import ChunkParserI\n",
    "\n",
    "class UnigramChunker(ChunkParserI):    \n",
    "    def __init__(self, train_sents):\n",
    "        # convert train sents from tree format to tags\n",
    "        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        \n",
    "        # convert to tree again\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  66.3%%\n",
      "    Precision:     37.5%%\n",
      "    Recall:        18.5%%\n",
      "    F-Measure:     24.8%%\n"
     ]
    }
   ],
   "source": [
    "# unigram chunker \n",
    "unigram_chunker = UnigramChunker(train_trees)\n",
    "print(unigram_chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, precision and recall have of course improved compared to the previous dummy parser. Let's also look at what the unigram parser has learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CC', 'O'), ('CD', 'B-round_trip'), ('DT', 'O'), ('EX', 'O'), ('FW', 'B-fromloc.city_name'), ('IN', 'O'), ('JJ', 'O'), ('JJR', 'B-cost_relative'), ('JJS', 'B-cost_relative'), ('MD', 'O'), ('NN', 'O'), ('NNP', 'B-depart_time.time'), ('NNS', 'O'), ('PDT', 'O'), ('POS', 'O'), ('PRP', 'O'), ('PRP$', 'O'), ('RB', 'O'), ('RBR', 'B-cost_relative'), ('RBS', 'B-cost_relative'), ('RP', 'O'), ('TO', 'O'), ('VB', 'B-toloc.city_name'), ('VBD', 'O'), ('VBG', 'O'), ('VBN', 'O'), ('VBP', 'O'), ('VBZ', 'O'), ('WDT', 'O'), ('WP', 'O'), ('WRB', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# printing the most likely IOB tags for each POS tag\n",
    "\n",
    "# extract the list of pos tags\n",
    "postags = sorted(set([pos for sent in train_trees for (word, pos) in sent.leaves()]))\n",
    "\n",
    "# for each tag, assign the most likely IOB label\n",
    "print(unigram_chunker.tagger.tag(postags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unigram tagger has learnt that most pos tags are indeed an 'O', i.e. don't form an entity. Some interesting patterns it has learnt are:\n",
    "- JJR, JJS (relative adjectives), are most likely B-cost_relative (e.g. cheapest, cheaper)\n",
    "- NNP is most likely to be B-depart_time.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Chunker\n",
    "\n",
    "Let's try a bigram chunker as well - we just need to change the ```UnigramTagger``` to ```BigramTagger```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram tagger\n",
    "\n",
    "class BigramChunker(ChunkParserI):    \n",
    "    def __init__(self, train_sents):\n",
    "        # convert train sents from tree format to tags\n",
    "        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)] \n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)\n",
    "        \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        \n",
    "        # convert to tree again\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag) in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  70.6%%\n",
      "    Precision:     43.5%%\n",
      "    Recall:        38.8%%\n",
      "    F-Measure:     41.0%%\n"
     ]
    }
   ],
   "source": [
    "# unigram chunker \n",
    "bigram_chunker = BigramChunker(train_trees)\n",
    "print(bigram_chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have improved significantly from unigram to bigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Based Chunkers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutiveNPChunkTagger(nltk.TaggerI): \n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = npchunk_features(untagged_sent, i, history) \n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = npchunk_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)\n",
    "\n",
    "class ConsecutiveNPChunker(nltk.ChunkParserI): \n",
    "    def __init__(self, train_sents):\n",
    "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
    "                         nltk.chunk.tree2conlltags(sent)]\n",
    "                        for sent in train_sents]\n",
    "        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        tagged_sents = self.tagger.tag(sentence)\n",
    "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features for a given word i in a given sentence \n",
    "# history refers to the previous POS tags in the sentence\n",
    "def npchunk_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    # the first word has both previous word and previous tag undefined\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "\n",
    "    # gazetteer lookup features (see section below)\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "\n",
    "    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word,\n",
    "           'word_is_city': gazetteer[0],\n",
    "           'word_is_state': gazetteer[1],\n",
    "           'word_is_county': gazetteer[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP'),\n",
       " ('flights', 'NNS'),\n",
       " ('leave', 'VBP'),\n",
       " ('atlanta', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('about', 'RB'),\n",
       " ('DIGIT', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('afternoon', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('arrive', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('san', 'JJ'),\n",
       " ('francisco', 'NN')]"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example features for a given sentence\n",
    "sent_pos = train_pos[0]\n",
    "sent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 'WP', 'prevpos': '<START>', 'word': 'what', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NNS', 'prevpos': 'WP', 'word': 'flights', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'VBP', 'prevpos': 'NNS', 'word': 'leave', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'VBN', 'prevpos': 'VBP', 'word': 'atlanta', 'word_is_city': True, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'VBN', 'word': 'at', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'RB', 'prevpos': 'IN', 'word': 'about', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NNP', 'prevpos': 'RB', 'word': 'DIGIT', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'NNP', 'word': 'in', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'DT', 'prevpos': 'IN', 'word': 'the', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'DT', 'word': 'afternoon', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'CC', 'prevpos': 'NN', 'word': 'and', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'CC', 'word': 'arrive', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'IN', 'prevpos': 'NN', 'word': 'in', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'JJ', 'prevpos': 'IN', 'word': 'san', 'word_is_city': False, 'word_is_state': False, 'word_is_county': False}\n",
      " \n",
      "{'pos': 'NN', 'prevpos': 'JJ', 'word': 'francisco', 'word_is_city': True, 'word_is_state': False, 'word_is_county': False}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# example features for a sentence\n",
    "for i in range(len(sent_pos)):\n",
    "    print(npchunk_features(sent_pos, i, history=[]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the chunker \n",
    "chunker = ConsecutiveNPChunker(train_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  91.7%%\n",
      "    Precision:     75.3%%\n",
      "    Recall:        81.8%%\n",
      "    F-Measure:     78.4%%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the chunker\n",
    "print(chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results have improved significantly compared to the basic unigram/bigram chunkers, and they may improve further if we create better features.\n",
    "\n",
    "For example, if the word is 'DIGIT' (numbers are labelled as 'DIGIT' in this dataset), we can have a feature which indicates that (see example below). In this dataset, 4-digit numbers are encoded as 'DIGITDIGITDIGITDIGIT'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('DIGITDIGITDIGIT', 'NNP'),\n",
       " ('flight', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('denver', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('san', 'VB'),\n",
       " ('francisco', 'NN')]"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of 'DIGITDIGIT'\n",
    "train_pos[1326]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some of these features and see if the performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features for a given word i in a given sentence \n",
    "# history refers to the previous POS tags in the sentence\n",
    "def npchunk_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    # the first word has both previous word and previous tag undefined\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "        \n",
    "    if i == len(sentence)-1:\n",
    "        nextword, nextpos = '<END>', '<END>'\n",
    "    else:\n",
    "        nextword, nextpos = sentence[i+1]\n",
    "\n",
    "    # gazetteer lookup features (see section below)\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "\n",
    "    # adding word_is_digit feature (boolean)\n",
    "    return {\"pos\": pos, \"prevpos\": prevpos, 'word':word, \n",
    "           'word_is_city': gazetteer[0],\n",
    "           'word_is_state': gazetteer[1],\n",
    "           'word_is_county': gazetteer[2],\n",
    "           'word_is_digit': word in 'DIGITDIGITDIGIT', \n",
    "           'nextword': nextword, \n",
    "           'nextpos': nextpos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  91.7%%\n",
      "    Precision:     75.9%%\n",
      "    Recall:        85.1%%\n",
      "    F-Measure:     80.3%%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate the chunker \n",
    "chunker = ConsecutiveNPChunker(train_trees)\n",
    "print(chunker.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ChunkParse score:\n",
    "#     IOB Accuracy:  92.7%%\n",
    "#     Precision:     78.1%%\n",
    "#     Recall:        84.9%%\n",
    "#     F-Measure:     81.4%%\n",
    "\n",
    "# ChunkParse score:\n",
    "#     IOB Accuracy:  91.7%%\n",
    "#     Precision:     75.5%%\n",
    "#     Recall:        82.0%%\n",
    "#     F-Measure:     78.6%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Gazetteer to Lookup Cities and States\n",
    "\n",
    "URL: https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State short</th>\n",
       "      <th>State full</th>\n",
       "      <th>County</th>\n",
       "      <th>City alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Internal Revenue Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Holtsville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>URB San Joaquin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Jard De Adjuntas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Colinas Del Gigante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State short   State full    County                City alias\n",
       "0  Holtsville          NY     New York   SUFFOLK  Internal Revenue Service\n",
       "1  Holtsville          NY     New York   SUFFOLK                Holtsville\n",
       "2    Adjuntas          PR  Puerto Rico  ADJUNTAS           URB San Joaquin\n",
       "3    Adjuntas          PR  Puerto Rico  ADJUNTAS          Jard De Adjuntas\n",
       "4    Adjuntas          PR  Puerto Rico  ADJUNTAS       Colinas Del Gigante"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading a file containing list of US cities, states and counties\n",
    "us_cities = pd.read_csv(\"us_cities_states_counties.csv\", sep=\"|\")\n",
    "us_cities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing cities, states and counties as sets\n",
    "cities = set(us_cities['City'].str.lower())\n",
    "states = set(us_cities['State full'].str.lower())\n",
    "counties = set(us_cities['County'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18854\n",
      "62\n",
      "1932\n"
     ]
    }
   ],
   "source": [
    "print(len(cities))\n",
    "print(len(states))\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to look up a given word in cities, states, county\n",
    "def gazetteer_lookup(word):\n",
    "    return (word in cities, word in states, word in counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, True)\n",
      "(False, True, True)\n",
      "(True, False, True)\n"
     ]
    }
   ],
   "source": [
    "# sample lookups\n",
    "print(gazetteer_lookup('washington'))\n",
    "print(gazetteer_lookup('utah'))\n",
    "print(gazetteer_lookup('philadelphia'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF Based Taggers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('flights', 'NNS', 'O'),\n",
       " ('leave', 'VBP', 'O'),\n",
       " ('atlanta', 'VBN', 'B-fromloc.city_name'),\n",
       " ('at', 'IN', 'O'),\n",
       " ('about', 'RB', 'B-depart_time.time_relative'),\n",
       " ('DIGIT', 'NNP', 'B-depart_time.time'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('afternoon', 'NN', 'B-depart_time.period_of_day'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('arrive', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('san', 'JJ', 'B-toloc.city_name'),\n",
       " ('francisco', 'NN', 'I-toloc.city_name')]"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structure of train/validation data\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to extract features from a given sentence. This is similar to the ```npchunk_features()``` function defined above, but we'll add some new features as well such as the suffix of the word (upto the last 4 characters), prefix (upto first 4 characters) etc.\n",
    "\n",
    "The list of features we'll extract is as follows:\n",
    "```\n",
    "{\n",
    "            'word':word,\n",
    "            'pos': pos, \n",
    "            'prevword': prevword,\n",
    "            'prevpos': prevpos,  \n",
    "            'nextword': nextword, \n",
    "            'nextpos': nextpos,\n",
    "            'word_is_city': gazetteer[0],\n",
    "            'word_is_state': gazetteer[1],\n",
    "            'word_is_county': gazetteer[2],\n",
    "            'word_is_digit': word in 'DIGITDIGITDIGIT',\n",
    "            'suff_1': suff_1,  \n",
    "            'suff_2': suff_2,  \n",
    "            'suff_3': suff_3,  \n",
    "            'suff_4': suff_4, \n",
    "            'pref_1': pref_1,  \n",
    "            'pref_2': pref_2,  \n",
    "            'pref_3': pref_3, \n",
    "            'pref_4': pref_4 \n",
    "\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other features to consider\n",
    "\n",
    "# airline code\n",
    "# airline name\n",
    "# day name (monday/tuesday etc.) i=1847, 2769\n",
    "# o'clock (word shape): i=379\n",
    "\n",
    "# i=random.randrange(len(train_labels))\n",
    "# train_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from a given sentence\n",
    "def word_features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    pos = sent[i][1]\n",
    "    \n",
    "    # first word\n",
    "    if i==0:\n",
    "        prevword = '<START>'\n",
    "        prevpos = '<START>'\n",
    "    else:\n",
    "        prevword = sent[i-1][0]\n",
    "        prevpos = sent[i-1][1]\n",
    "    \n",
    "    # last word\n",
    "    if i == len(sent)-1:\n",
    "        nextword = '<END>'\n",
    "        nextpos = '<END>'\n",
    "    else:\n",
    "        nextword = sent[i+1][0]\n",
    "        nextpos = sent[i+1][1]\n",
    "    \n",
    "    # word is in gazetteer\n",
    "    gazetteer = gazetteer_lookup(word)\n",
    "    \n",
    "    # suffixes and prefixes\n",
    "    pref_1, pref_2, pref_3, pref_4 = word[:1], word[:2], word[:3], word[:4]\n",
    "    suff_1, suff_2, suff_3, suff_4 = word[-1:], word[-2:], word[-3:], word[-4:]\n",
    "    \n",
    "    return {'word':word,\n",
    "            'pos': pos, \n",
    "            'prevword': prevword,\n",
    "            'prevpos': prevpos,  \n",
    "            'nextword': nextword, \n",
    "            'nextpos': nextpos,\n",
    "            'word_is_city': gazetteer[0],\n",
    "            'word_is_state': gazetteer[1],\n",
    "            'word_is_county': gazetteer[2],\n",
    "            'word_is_digit': word in 'DIGITDIGITDIGIT',\n",
    "            'suff_1': suff_1,  \n",
    "            'suff_2': suff_2,  \n",
    "            'suff_3': suff_3,  \n",
    "            'suff_4': suff_4, \n",
    "            'pref_1': pref_1,  \n",
    "            'pref_2': pref_2,  \n",
    "            'pref_3': pref_3, \n",
    "            'pref_4': pref_4 }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nextpos': 'IN',\n",
       " 'nextword': 'at',\n",
       " 'pos': 'VBN',\n",
       " 'pref_1': 'a',\n",
       " 'pref_2': 'at',\n",
       " 'pref_3': 'atl',\n",
       " 'pref_4': 'atla',\n",
       " 'prevpos': 'VBP',\n",
       " 'prevword': 'leave',\n",
       " 'suff_1': 'a',\n",
       " 'suff_2': 'ta',\n",
       " 'suff_3': 'nta',\n",
       " 'suff_4': 'anta',\n",
       " 'word': 'atlanta',\n",
       " 'word_is_city': True,\n",
       " 'word_is_county': False,\n",
       " 'word_is_digit': False,\n",
       " 'word_is_state': False}"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example features\n",
    "word_features(train_labels[0], i=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a few more functions to extract featrues, labels, words from sentences\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word_features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation and test sets\n",
    "X_train = [sent2features(s) for s in train_labels]\n",
    "y_train = [sent2labels(s) for s in train_labels]\n",
    "\n",
    "X_valid = [sent2features(s) for s in valid_labels]\n",
    "y_valid = [sent2labels(s) for s in valid_labels]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_labels]\n",
    "y_test = [sent2labels(s) for s in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nextpos': 'NNS',\n",
       "  'nextword': 'flights',\n",
       "  'pos': 'WP',\n",
       "  'pref_1': 'w',\n",
       "  'pref_2': 'wh',\n",
       "  'pref_3': 'wha',\n",
       "  'pref_4': 'what',\n",
       "  'prevpos': '<START>',\n",
       "  'prevword': '<START>',\n",
       "  'suff_1': 't',\n",
       "  'suff_2': 'at',\n",
       "  'suff_3': 'hat',\n",
       "  'suff_4': 'what',\n",
       "  'word': 'what',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False},\n",
       " {'nextpos': 'VBP',\n",
       "  'nextword': 'leave',\n",
       "  'pos': 'NNS',\n",
       "  'pref_1': 'f',\n",
       "  'pref_2': 'fl',\n",
       "  'pref_3': 'fli',\n",
       "  'pref_4': 'flig',\n",
       "  'prevpos': 'WP',\n",
       "  'prevword': 'what',\n",
       "  'suff_1': 's',\n",
       "  'suff_2': 'ts',\n",
       "  'suff_3': 'hts',\n",
       "  'suff_4': 'ghts',\n",
       "  'word': 'flights',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False},\n",
       " {'nextpos': 'VBN',\n",
       "  'nextword': 'atlanta',\n",
       "  'pos': 'VBP',\n",
       "  'pref_1': 'l',\n",
       "  'pref_2': 'le',\n",
       "  'pref_3': 'lea',\n",
       "  'pref_4': 'leav',\n",
       "  'prevpos': 'NNS',\n",
       "  'prevword': 'flights',\n",
       "  'suff_1': 'e',\n",
       "  'suff_2': 've',\n",
       "  'suff_3': 'ave',\n",
       "  'suff_4': 'eave',\n",
       "  'word': 'leave',\n",
       "  'word_is_city': False,\n",
       "  'word_is_county': False,\n",
       "  'word_is_digit': False,\n",
       "  'word_is_state': False}]"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is a list of sentences within which each feature has a corresponding dict of features\n",
    "# first few words of the first sentence in X_train\n",
    "X_train[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a CRF trainer from pycrfsuite\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "# create (word_features, word_label) pairs for every sentence\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters - using L-BFGS training algorithm (default) with Elastic Net (L1 + L2) regularization.\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of possible params\n",
    "trainer.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the trained model to a file\n",
    "trainer.train('atis.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x33ae9b0>"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tagger object and open the trained file\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('atis.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what aircraft is used on delta flight DIGITDIGITDIGITDIGIT from kansas city to salt lake city\n"
     ]
    }
   ],
   "source": [
    "# tagging a sample sentence\n",
    "sample_sent = valid_labels[0]\n",
    "print(' '.join(sent2tokens(sample_sent)), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: O O O O O B-airline_name O B-flight_number O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name\n",
      "\n",
      "\n",
      "Correct:   O O O O O B-airline_name O B-flight_number O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(sample_sent))))\n",
    "print('\\n')\n",
    "print(\"Correct:  \", ' '.join(sent2labels(sample_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iob_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of IOB-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    # note that we are not including 'O' as a class\n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-airline_name',\n",
       " 'O',\n",
       " 'B-flight_number',\n",
       " 'O',\n",
       " 'B-fromloc.city_name',\n",
       " 'I-fromloc.city_name',\n",
       " 'O',\n",
       " 'B-toloc.city_name',\n",
       " 'I-toloc.city_name',\n",
       " 'I-toloc.city_name']"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_valid]\n",
    "\n",
    "# predictions for first sentence\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the model. Since we are dealing with a multiclass classification problem, we can use sklearn's ```LabelBinarizer``` to binarize labels in a one-versus-all manner.  \n",
    "\n",
    "Read about LabelBinarizer here: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "             B-aircraft_code       1.00      0.33      0.50         3\n",
      "              B-airline_code       1.00      0.93      0.96        27\n",
      "              B-airline_name       1.00      0.99      1.00       139\n",
      "              I-airline_name       1.00      0.97      0.99        80\n",
      "              B-airport_code       0.67      0.80      0.73         5\n",
      "              B-airport_name       0.50      0.43      0.46         7\n",
      "              I-airport_name       0.67      0.44      0.53         9\n",
      " B-arrive_date.date_relative       0.00      0.00      0.00         1\n",
      "      B-arrive_date.day_name       0.25      0.07      0.11        14\n",
      "    B-arrive_date.day_number       0.50      0.12      0.19        17\n",
      "    I-arrive_date.day_number       0.00      0.00      0.00         2\n",
      "    B-arrive_date.month_name       0.50      0.12      0.19        17\n",
      "B-arrive_date.today_relative       0.00      0.00      0.00         2\n",
      "      B-arrive_time.end_time       1.00      0.71      0.83         7\n",
      "      I-arrive_time.end_time       1.00      0.83      0.91         6\n",
      "    B-arrive_time.period_mod       0.00      0.00      0.00         1\n",
      " B-arrive_time.period_of_day       0.00      0.00      0.00         9\n",
      "    B-arrive_time.start_time       1.00      0.71      0.83         7\n",
      "    I-arrive_time.start_time       1.00      1.00      1.00         3\n",
      "          B-arrive_time.time       0.84      0.60      0.70        43\n",
      "          I-arrive_time.time       0.85      0.63      0.72        35\n",
      " B-arrive_time.time_relative       0.85      0.62      0.72        37\n",
      " I-arrive_time.time_relative       0.00      0.00      0.00         2\n",
      "                 B-city_name       0.74      0.40      0.52        43\n",
      "                 I-city_name       0.45      0.71      0.56         7\n",
      "                B-class_type       0.98      0.94      0.96        47\n",
      "                I-class_type       0.97      1.00      0.99        38\n",
      "                   B-connect       0.89      0.89      0.89         9\n",
      "             B-cost_relative       1.00      1.00      1.00        60\n",
      "             I-cost_relative       0.80      1.00      0.89         4\n",
      " B-depart_date.date_relative       0.85      0.85      0.85        13\n",
      "      B-depart_date.day_name       0.92      0.98      0.95       161\n",
      "    B-depart_date.day_number       0.83      0.98      0.90        82\n",
      "    I-depart_date.day_number       0.88      0.96      0.92        23\n",
      "    B-depart_date.month_name       0.82      0.99      0.90        75\n",
      "B-depart_date.today_relative       0.92      1.00      0.96        23\n",
      "          B-depart_date.year       1.00      1.00      1.00         8\n",
      "      B-depart_time.end_time       0.50      1.00      0.67         2\n",
      "      I-depart_time.end_time       0.50      1.00      0.67         1\n",
      "    B-depart_time.period_mod       0.81      0.93      0.87        14\n",
      " B-depart_time.period_of_day       0.92      0.95      0.93       136\n",
      "    B-depart_time.start_time       0.50      1.00      0.67         2\n",
      "    I-depart_time.start_time       1.00      1.00      1.00         1\n",
      "          B-depart_time.time       0.77      0.93      0.84        74\n",
      "          I-depart_time.time       0.78      0.93      0.85        56\n",
      " B-depart_time.time_relative       0.79      0.93      0.86        61\n",
      "                   B-economy       1.00      1.00      1.00         9\n",
      "                   I-economy       1.00      1.00      1.00         2\n",
      "               B-fare_amount       1.00      1.00      1.00         5\n",
      "               I-fare_amount       1.00      1.00      1.00         5\n",
      "           B-fare_basis_code       1.00      0.88      0.93        16\n",
      "               B-flight_days       1.00      1.00      1.00         4\n",
      "                B-flight_mod       0.98      0.93      0.96        70\n",
      "                I-flight_mod       0.00      0.00      0.00         2\n",
      "             B-flight_number       1.00      0.90      0.95        21\n",
      "               B-flight_stop       1.00      0.89      0.94        38\n",
      "               I-flight_stop       1.00      0.33      0.50         6\n",
      "               B-flight_time       0.91      0.83      0.87        12\n",
      "               I-flight_time       0.83      0.83      0.83         6\n",
      "      B-fromloc.airport_code       1.00      0.40      0.57         5\n",
      "      B-fromloc.airport_name       0.75      0.75      0.75        20\n",
      "      I-fromloc.airport_name       0.81      0.76      0.79        29\n",
      "         B-fromloc.city_name       0.99      0.98      0.98       868\n",
      "         I-fromloc.city_name       0.94      0.99      0.97       134\n",
      "        B-fromloc.state_code       1.00      0.93      0.96        14\n",
      "        B-fromloc.state_name       1.00      0.75      0.86        12\n",
      "        I-fromloc.state_name       1.00      0.33      0.50         3\n",
      "                      B-meal       1.00      1.00      1.00        11\n",
      "          B-meal_description       1.00      1.00      1.00        12\n",
      "                       B-mod       0.50      1.00      0.67         2\n",
      "                        B-or       1.00      0.95      0.97        20\n",
      "          B-restriction_code       1.00      0.83      0.91         6\n",
      "          I-restriction_code       1.00      1.00      1.00         1\n",
      " B-return_date.date_relative       1.00      0.50      0.67         2\n",
      "    B-return_date.day_number       0.00      0.00      0.00         1\n",
      "    I-return_date.day_number       0.00      0.00      0.00         1\n",
      "    B-return_date.month_name       0.00      0.00      0.00         1\n",
      "    B-return_time.period_mod       0.00      0.00      0.00         1\n",
      " B-return_time.period_of_day       0.00      0.00      0.00         2\n",
      "                B-round_trip       1.00      1.00      1.00        62\n",
      "                I-round_trip       1.00      1.00      1.00        61\n",
      "                B-state_code       0.33      1.00      0.50         1\n",
      "         B-stoploc.city_name       0.66      0.85      0.74        54\n",
      "         I-stoploc.city_name       0.50      0.50      0.50         6\n",
      "        B-stoploc.state_code       0.00      0.00      0.00         1\n",
      "        B-toloc.airport_code       1.00      0.75      0.86         4\n",
      "        B-toloc.airport_name       0.78      0.64      0.70        11\n",
      "        I-toloc.airport_name       0.67      0.77      0.71        13\n",
      "           B-toloc.city_name       0.96      0.98      0.97       860\n",
      "           I-toloc.city_name       0.99      0.98      0.99       241\n",
      "          B-toloc.state_code       1.00      1.00      1.00        19\n",
      "          B-toloc.state_name       1.00      1.00      1.00        22\n",
      "          I-toloc.state_name       1.00      1.00      1.00         4\n",
      "            B-transport_type       1.00      0.78      0.88         9\n",
      "            I-transport_type       1.00      1.00      1.00         4\n",
      "\n",
      "                 avg / total       0.93      0.93      0.92      4126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(iob_classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create (word, pos_tag, predicted_iob_label) tuples for a given dataset\n",
    "def append_predicted_tags(pos_tagged_data, labels):\n",
    "    iob_labels = []\n",
    "    for sent in list(zip(pos_tagged_data, labels)):\n",
    "        pos = sent[0]\n",
    "        labels = sent[1]\n",
    "        l = list(zip(pos, labels))\n",
    "        tuple_3 = [(i[0][0], i[0][1], i[1]) for i in l]\n",
    "        iob_labels.append(tuple_3)\n",
    "    return iob_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('aircraft', 'NN', 'O'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('used', 'VBN', 'O'),\n",
       " ('on', 'IN', 'O'),\n",
       " ('delta', 'JJ', 'B-airline_name'),\n",
       " ('flight', 'NN', 'O'),\n",
       " ('DIGITDIGITDIGITDIGIT', 'NNP', 'B-flight_number'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('kansas', 'NNP', 'B-fromloc.city_name'),\n",
       " ('city', 'NN', 'I-fromloc.city_name'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('salt', 'VB', 'B-toloc.city_name'),\n",
       " ('lake', 'JJ', 'I-toloc.city_name'),\n",
       " ('city', 'NN', 'I-toloc.city_name')]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions of IOB tags on a sample validation query \n",
    "valid_tags = append_predicted_tags(valid_pos, y_pred)\n",
    "valid_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  what/WP\n",
      "  aircraft/NN\n",
      "  is/VBZ\n",
      "  used/VBN\n",
      "  on/IN\n",
      "  (airline_name delta/JJ)\n",
      "  flight/NN\n",
      "  (flight_number DIGITDIGITDIGITDIGIT/NNP)\n",
      "  from/IN\n",
      "  (fromloc.city_name kansas/NNP city/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name salt/VB lake/JJ city/NN))\n"
     ]
    }
   ],
   "source": [
    "# create a tree using the assigned iob labels\n",
    "valid_trees = [conlltags2tree(sent) for sent in valid_tags]\n",
    "print(valid_trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the CRF Classifier\n",
    "\n",
    "Let's now try to understand what the classifier has learnt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at the docs of tagger.info() for a list of attributes etc.\n",
    "info = tagger.info()\n",
    "# help(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('word_is_state', 'B-toloc.state_name'), 6.570057),\n",
       " (('pref_1:q', 'B-fare_basis_code'), 5.607318),\n",
       " (('prevword:round', 'I-round_trip'), 5.405693),\n",
       " (('prevword:arrive', 'B-arrive_time.time_relative'), 5.079029),\n",
       " (('word_is_state', 'B-fromloc.state_name'), 5.073412),\n",
       " (('prevword:arriving', 'B-arrive_time.time_relative'), 5.001828),\n",
       " (('prevword:restriction', 'B-restriction_code'), 4.829951),\n",
       " (('prevword:from', 'B-fromloc.city_name'), 4.730971),\n",
       " (('prevword:code', 'B-fare_basis_code'), 4.47244),\n",
       " (('prevword:between', 'B-depart_time.start_time'), 4.427766),\n",
       " (('nextword:afternoon', 'B-depart_time.period_of_day'), 4.300173),\n",
       " (('prevword:flight', 'B-flight_number'), 4.230575),\n",
       " (('pos:DT', 'O'), 4.179398),\n",
       " (('nextword:morning', 'B-depart_time.period_of_day'), 4.125129),\n",
       " (('suff_4:test', 'B-flight_mod'), 4.120814),\n",
       " (('prevword:between', 'B-arrive_time.start_time'), 3.948435),\n",
       " (('pref_1:r', 'B-round_trip'), 3.852988),\n",
       " (('pref_2:ap', 'B-restriction_code'), 3.822704),\n",
       " (('prevword:same', 'B-return_date.date_relative'), 3.816333),\n",
       " (('prevword:st.', 'I-toloc.city_name'), 3.665354)]"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# top 20 features, and the labels they predict\n",
    "Counter(info.state_features).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I-today_relative', 'I-today_relative'), 7.861919),\n",
       " (('B-toloc.airport_name', 'I-toloc.airport_name'), 7.42822),\n",
       " (('I-depart_date.today_relative', 'I-depart_date.today_relative'), 7.341),\n",
       " (('B-airport_name', 'I-airport_name'), 7.249586),\n",
       " (('B-return_date.month_name', 'B-return_date.day_number'), 7.072054),\n",
       " (('B-arrive_date.month_name', 'B-arrive_date.day_number'), 6.808602),\n",
       " (('B-fromloc.state_name', 'I-fromloc.state_name'), 6.793063),\n",
       " (('B-fromloc.airport_name', 'I-fromloc.airport_name'), 6.785764),\n",
       " (('B-transport_type', 'I-transport_type'), 6.636065),\n",
       " (('B-arrive_time.period_of_day', 'I-arrive_time.period_of_day'), 6.570275),\n",
       " (('B-city_name', 'I-city_name'), 6.388733),\n",
       " (('B-arrive_time.end_time', 'I-arrive_time.end_time'), 6.24598),\n",
       " (('B-depart_date.month_name', 'B-depart_date.day_number'), 6.240609),\n",
       " (('B-depart_time.end_time', 'I-depart_time.end_time'), 6.239169),\n",
       " (('B-stoploc.city_name', 'I-stoploc.city_name'), 6.23242)]"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top likely transitions the model has learnt\n",
    "Counter(info.transitions).most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "             B-aircraft_code       1.00      0.45      0.62        33\n",
      "              B-airline_code       0.97      0.85      0.91        34\n",
      "              B-airline_name       0.99      0.98      0.99       101\n",
      "              I-airline_name       0.95      0.95      0.95        65\n",
      "              B-airport_code       0.44      0.44      0.44         9\n",
      "              B-airport_name       0.88      0.33      0.48        21\n",
      "              I-airport_name       0.77      0.34      0.48        29\n",
      " B-arrive_date.date_relative       0.50      0.50      0.50         2\n",
      "      B-arrive_date.day_name       0.71      0.45      0.56        11\n",
      "    B-arrive_date.day_number       0.00      0.00      0.00         6\n",
      "    B-arrive_date.month_name       0.00      0.00      0.00         6\n",
      "      B-arrive_time.end_time       0.00      0.00      0.00         8\n",
      "      I-arrive_time.end_time       0.00      0.00      0.00         8\n",
      " B-arrive_time.period_of_day       0.00      0.00      0.00         6\n",
      "    B-arrive_time.start_time       0.75      0.75      0.75         8\n",
      "    I-arrive_time.start_time       0.00      0.00      0.00         1\n",
      "          B-arrive_time.time       0.81      0.74      0.77        34\n",
      "          I-arrive_time.time       0.81      0.74      0.78        35\n",
      " B-arrive_time.time_relative       0.89      0.77      0.83        31\n",
      " I-arrive_time.time_relative       0.00      0.00      0.00         4\n",
      "             B-booking_class       0.00      0.00      0.00         1\n",
      "                 B-city_name       0.58      0.39      0.46        57\n",
      "                 I-city_name       0.41      0.30      0.35        30\n",
      "                B-class_type       0.96      1.00      0.98        24\n",
      "                I-class_type       1.00      1.00      1.00        17\n",
      "               B-compartment       0.00      0.00      0.00         1\n",
      "                   B-connect       1.00      1.00      1.00         6\n",
      "             B-cost_relative       1.00      0.97      0.99        37\n",
      "             I-cost_relative       1.00      0.67      0.80         3\n",
      "                  B-day_name       0.00      0.00      0.00         2\n",
      "                 B-days_code       0.00      0.00      0.00         1\n",
      " B-depart_date.date_relative       0.89      0.94      0.91        17\n",
      "      B-depart_date.day_name       0.96      0.99      0.97       212\n",
      "    B-depart_date.day_number       0.90      1.00      0.95        55\n",
      "    I-depart_date.day_number       1.00      1.00      1.00        15\n",
      "    B-depart_date.month_name       0.90      0.98      0.94        56\n",
      "B-depart_date.today_relative       0.89      0.89      0.89         9\n",
      "          B-depart_date.year       1.00      1.00      1.00         3\n",
      "      B-depart_time.end_time       0.22      0.67      0.33         3\n",
      "      I-depart_time.end_time       0.22      0.67      0.33         3\n",
      "    B-depart_time.period_mod       0.71      1.00      0.83         5\n",
      " B-depart_time.period_of_day       0.94      0.92      0.93       130\n",
      " I-depart_time.period_of_day       1.00      1.00      1.00         1\n",
      "    B-depart_time.start_time       0.50      0.33      0.40         3\n",
      "    I-depart_time.start_time       0.50      1.00      0.67         1\n",
      "          B-depart_time.time       0.74      0.91      0.82        57\n",
      "          I-depart_time.time       0.84      0.90      0.87        52\n",
      " B-depart_time.time_relative       0.91      0.94      0.92        65\n",
      " I-depart_time.time_relative       0.00      0.00      0.00         1\n",
      "                   B-economy       1.00      1.00      1.00         6\n",
      "               B-fare_amount       1.00      1.00      1.00         2\n",
      "               I-fare_amount       1.00      1.00      1.00         2\n",
      "           B-fare_basis_code       0.89      0.94      0.91        17\n",
      "                    B-flight       0.00      0.00      0.00         1\n",
      "               B-flight_days       1.00      1.00      1.00        10\n",
      "                B-flight_mod       1.00      0.96      0.98        24\n",
      "                I-flight_mod       0.00      0.00      0.00         6\n",
      "             B-flight_number       0.92      1.00      0.96        11\n",
      "             I-flight_number       0.00      0.00      0.00         1\n",
      "               B-flight_stop       1.00      1.00      1.00        21\n",
      "               B-flight_time       1.00      1.00      1.00         1\n",
      "               I-flight_time       1.00      1.00      1.00         1\n",
      "      B-fromloc.airport_code       1.00      1.00      1.00         5\n",
      "      B-fromloc.airport_name       0.52      0.92      0.67        12\n",
      "      I-fromloc.airport_name       0.54      1.00      0.70        15\n",
      "         B-fromloc.city_name       0.98      0.99      0.99       704\n",
      "         I-fromloc.city_name       0.94      0.98      0.96       177\n",
      "        B-fromloc.state_code       1.00      1.00      1.00        23\n",
      "        B-fromloc.state_name       1.00      0.76      0.87        17\n",
      "        I-fromloc.state_name       0.00      0.00      0.00         1\n",
      "                      B-meal       0.94      1.00      0.97        16\n",
      "                 B-meal_code       0.00      0.00      0.00         1\n",
      "          B-meal_description       1.00      0.80      0.89        10\n",
      "                       B-mod       0.00      0.00      0.00         2\n",
      "                        B-or       0.50      1.00      0.67         3\n",
      "             B-period_of_day       0.00      0.00      0.00         4\n",
      "          B-restriction_code       1.00      0.75      0.86         4\n",
      "          I-restriction_code       1.00      1.00      1.00         3\n",
      " B-return_date.date_relative       0.00      0.00      0.00         3\n",
      " I-return_date.date_relative       0.00      0.00      0.00         3\n",
      "      B-return_date.day_name       0.00      0.00      0.00         2\n",
      "                B-round_trip       0.99      0.97      0.98        73\n",
      "                I-round_trip       1.00      1.00      1.00        71\n",
      "                B-state_code       0.50      1.00      0.67         1\n",
      "                B-state_name       0.00      0.00      0.00         9\n",
      "                I-state_name       0.00      0.00      0.00         1\n",
      "      B-stoploc.airport_code       0.00      0.00      0.00         1\n",
      "         B-stoploc.city_name       0.50      0.60      0.55        20\n",
      "         I-stoploc.city_name       0.71      0.50      0.59        10\n",
      "        B-toloc.airport_code       0.00      0.00      0.00         4\n",
      "        B-toloc.airport_name       0.43      1.00      0.60         3\n",
      "        I-toloc.airport_name       0.33      1.00      0.50         3\n",
      "           B-toloc.city_name       0.96      0.97      0.97       716\n",
      "           I-toloc.city_name       0.94      0.97      0.95       265\n",
      "        B-toloc.country_name       0.00      0.00      0.00         1\n",
      "          B-toloc.state_code       1.00      0.94      0.97        18\n",
      "          B-toloc.state_name       0.73      0.79      0.76        28\n",
      "          I-toloc.state_name       0.33      1.00      0.50         1\n",
      "            B-transport_type       1.00      0.80      0.89        10\n",
      "            I-transport_type       0.00      0.00      0.00         1\n",
      "\n",
      "                 avg / total       0.90      0.90      0.90      3663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kshitij jain\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "print(iob_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing a Chunked Tree\n",
    "\n",
    "Now that we have labelled (chunked) the validation and test datasets, let's see how we can traverse the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may i have a listing of flights on monday from minneapolis to long beach california please \n",
      "\n",
      "depart_date.day_name [('monday', 'NN')]\n",
      "fromloc.city_name [('minneapolis', 'NNS')]\n",
      "toloc.city_name [('long', 'VB'), ('beach', 'NN')]\n",
      "toloc.state_name [('california', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "i = random.randrange(len(valid_trees))\n",
    "chunked_tree = valid_trees[i]\n",
    "\n",
    "print(' '.join([id_to_words[val] for val in val_x[i]]), '\\n')\n",
    "\n",
    "# traverse the tree and print labels of subtrees \n",
    "for n in chunked_tree:\n",
    "    if isinstance(n, nltk.tree.Tree):\n",
    "        print(n.label(), n.leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly parsed complex queries - i= 771, 25, 473, 23, 498, 893, 882, 694\n",
    "# ambiguous queries: not many so far\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all labels of train and validation trees\n",
    "tree_labels = []\n",
    "for tree in train_trees:\n",
    "    for n in tree:\n",
    "        if isinstance(n, nltk.tree.Tree):\n",
    "            tree_labels.append(n.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set has 78 unique labels\n",
    "label_set = set(tree_labels)\n",
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toloc.airport_code',\n",
       " 'cost_relative',\n",
       " 'return_date.day_name',\n",
       " 'aircraft_code',\n",
       " 'fare_basis_code',\n",
       " 'day_number',\n",
       " 'depart_time.start_time',\n",
       " 'depart_time.period_mod',\n",
       " 'return_date.date_relative',\n",
       " 'arrive_date.date_relative']"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first few labels\n",
    "list(label_set)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlightStats API Experiments\n",
    "\n",
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.flightstats.com/flex/schedules/rest/v1/json/from/ABQ/to/DFW/departing/2018/12/20?appId=9bed5b33&appKey=d7a448569ce9d0821da4fcc9f371e8cc\n"
     ]
    }
   ],
   "source": [
    "# flightstats API experiments\n",
    "app_id = '9bed5b33'\n",
    "app_key = 'd7a448569ce9d0821da4fcc9f371e8cc'\n",
    "\n",
    "base_url = 'https://api.flightstats.com/flex/schedules/rest/v1/json/from/'\n",
    "\n",
    "# {departureAirportCode}/to/{arrivalAirportCode}/departing/{year}/{month}/{day}\n",
    "# departing from ABQ to DFW on 20 Dec 2018\n",
    "extended_url = 'ABQ/to/DFW/departing/2018/12/20'\n",
    "\n",
    "# credentials\n",
    "creds = '?appId={0}&appKey={1}'.format(app_id, app_key)\n",
    "\n",
    "# complete url\n",
    "url = base_url + extended_url + creds\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "data = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrivalAirportFsCode': 'DFW',\n",
       " 'arrivalTime': '2018-12-20T09:37:00.000',\n",
       " 'carrierFsCode': 'AA',\n",
       " 'codeshares': [{'carrierFsCode': 'JL',\n",
       "   'flightNumber': '7231',\n",
       "   'referenceCode': 6844,\n",
       "   'serviceClasses': ['J', 'Y'],\n",
       "   'serviceType': 'J',\n",
       "   'trafficRestrictions': ['Q']},\n",
       "  {'carrierFsCode': 'BA',\n",
       "   'flightNumber': '5600',\n",
       "   'referenceCode': 7010,\n",
       "   'serviceClasses': ['R', 'J', 'Y'],\n",
       "   'serviceType': 'J',\n",
       "   'trafficRestrictions': ['Q']}],\n",
       " 'departureAirportFsCode': 'ABQ',\n",
       " 'departureTime': '2018-12-20T06:50:00.000',\n",
       " 'flightEquipmentIataCode': 'CR9',\n",
       " 'flightNumber': '5913',\n",
       " 'isCodeshare': False,\n",
       " 'isWetlease': True,\n",
       " 'referenceCode': '477-7022--',\n",
       " 'serviceClasses': ['R', 'J', 'Y'],\n",
       " 'serviceType': 'J',\n",
       " 'stops': 0,\n",
       " 'trafficRestrictions': [],\n",
       " 'wetleaseOperatorFsCode': 'YV'}"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample flight details\n",
    "data['scheduledFlights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.flightstats.com/api-docs/scheduledFlights/v1\n",
    "# https://developer.flightstats.com/api-docs/\n",
    "# https://developer.flightstats.com/api-docs/how_to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
