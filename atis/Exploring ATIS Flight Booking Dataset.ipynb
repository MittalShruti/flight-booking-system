{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATIS Flight Reservations Dataset\n",
    "\n",
    "Dataset download link: http://lisaweb.iro.umontreal.ca/transfert/lisa/users/mesnilgr/atis/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, pprint, os\n",
    "import gzip, os, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the first part of the dataset\n",
    "# each part (.gz file) contains train, validation and test sets, plus a dict\n",
    "\n",
    "filename = 'atis.fold0.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "try:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')\n",
    "except:\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3983)\n",
      "(3, 995)\n",
      "(3, 893)\n"
     ]
    }
   ],
   "source": [
    "# structure of the component data files\n",
    "print(np.shape(train_set))\n",
    "print(np.shape(valid_set))\n",
    "print(np.shape(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<class 'list'>\n",
      "3983\n"
     ]
    }
   ],
   "source": [
    "# each set is a 3-tuple, each element of the tuple being a list \n",
    "print(len(train_set))\n",
    "print(type(train_set[0]))\n",
    "print(len(train_set[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list has 3983 arrays, each array being a sentence. The words are encoded by numbers (and have to be decoded using the dict provided).\n",
    "\n",
    "Let's store the three lists into separate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the three elements of the tuple in three objects\n",
    "train_x, _, train_label = train_set\n",
    "val_x, _, val_label = valid_set\n",
    "test_x, _, test_label = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list represents the actual words (encoded), and the third list contains their labels (again, encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([554, 194, 268,  64,  62,  16,   8, 234, 481,  20,  40,  58, 234,\n",
       "       415, 205], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each list in the tuple is a numpy array (a sentence)\n",
    "# printing first list in the tuple's first element\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 126, 126,  48, 126,  36,  35, 126, 126,  33, 126, 126, 126,\n",
       "        78, 123], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels are stored in the third list train_label\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['tables2idx', 'words2idx', 'labels2idx'])\n"
     ]
    }
   ],
   "source": [
    "# dicts \n",
    "print(type(dicts))\n",
    "print(dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# each key:value pair is itself a dict\n",
    "print(type(dicts['labels2idx']))\n",
    "print(type(dicts['tables2idx']))\n",
    "print(type(dicts['words2idx']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing labels and words in separate variables\n",
    "words = dicts['words2idx']\n",
    "labels = dicts['labels2idx']\n",
    "tables = dicts['tables2idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nw', 'DIGIT', 'dc', 'louis', 'much', 'planes', 'departures', 'and', 'transcontinental', 'making', 'prices', 'three', 'some', 'midnight', 'define', 'atl', 'minneapolis', 'mco', 'find', 'database', 'now', 'philadelphia', 'night', 'than', 'dulles', 'serviced', 'up', 'latest', 'airline', 'pennsylvania', 'twenty', 'love', 'here', 'montreal', 'tuesdays', 'trying', '<UNK>', 'name', 'without', 'memphis', 'field', 'one', 'arrange', 'wednesday', 'friday', 'thirteenth', 'ua', 'cost', 'abbreviations', 'reservations', 'offer', 'serves', 'airport', 'arrives', 'rates', 'four', 'fifth', 'return', 'eighth', 'day', 'connect', 'milwaukee', 'thursday', 'limousine', 'ap80', 'see', 'cp', 'airports', 'live', 'over', 'list', 'quebec', 'business', 'weekday', 'sometime', 'california', 'meals', 'after', 'arrangements', 'tennessee', 'stands', 'listing', 'f', 'me', 'general', 'highest', 'airplane', 'friends', 'then', 'may', 'leaves', 'late', 'cheap', 'types', 'flight', 'least', 'there', 'leaving', 'most', 'thrift', 'westchester', 'm80', 'thank', 'round', 'daily', 'arrivals', 'nashville', 'no', 'march', 'angeles', 'rent', 'newark', 'DIGITDIGITDIGITDIGITDIGITDIGIT', 'service', 'does', 'air', 'these', 'sixth', 'seats', 'travel', 'has', 'could', 'what', 'pm', 'great', 'car', 'through', 'used', 'before', 'guardia', 'eastern', 'mitchell', 'florida', 'your', 'DIGITDIGITDIGIT', 'amount', 'trips', 'charlotte', 'well', 'they', 'goes', 'in', 'you', 'eleventh', 'q', 'missouri', 'passengers', 'reaching', 'paul', 'takeoffs', 'served', 'about', 'stop', 'weekdays', 'phoenix', 'schedules', 'qw', 'leave', 'mornings', 'tenth', 'are', 'ninth', 'use', 'cars', 'we', 'early', 'less', 'jose', 'saturdays', 'where', 'seating', 'coming', 'eighteenth', 'city', 'information', 'land', 'ten', 'oakland', 'numbers', 'c', 'provide', 'traveling', 'colorado', 'itinerary', 'departure', 'dfw', 'plane', 'either', 'would', 'which', 'from', 'departing', 'boeing', 'december', 'october', 'at', 'jfk', 'shortest', 'america', 'various', 'any', 'will', 'show', 'price', 'flights', 'expensive', 'seventeenth', 'can', 'interested', 'washington', 'but', 'twa', 'depart', 'thursdays', 'how', 'tell', 'dallas', 'book', 'ac', 'make', 'provided', 'thirty', 'meaning', 'nationair', 'is', 'noontime', 'know', 'm', 'midway', 'code', 'carries', 'burbank', 'alaska', 'lowest', 'fly', 'international', 'aircraft', 'tuesday', 'a', 'layover', 'sixteen', 'along', 'st.', 'buy', 'area', 'serve', 'distance', 'requesting', 'two', 'codes', 'breakfast', 'philly', 'say', 'fn', 'different', 'fort', 'during', 'i', 'ontario', 'nineteenth', 'michigan', 'd', 'snack', 'ap', \"'s\", 'last', 'eight', 'times', 'earliest', 'departs', 'look', 'their', 'nonstops', 'looking', 'fit', 'arriving', 'class', 'january', 'other', 'abbreviation', 'if', 'month', 'like', 'cincinnati', 'nonstop', 'ticket', 'restrictions', 'fifteenth', 'ewr', 'third', 'southwest', 'people', 'when', 'northwest', 'north', 'stopover', 'denver', 'boston', 'november', 'august', 'each', 'miami', 'include', 'takeoff', 'los', 'destination', 'take', 'canada', 'makes', 'flying', 'la', 'west', 'sorry', 'transport', 'chicago', 'this', 'soon', 'kansas', 'fourteenth', 'san', 'detroit', \"'re\", 'canadian', 'smallest', 's', 'very', 'back', 'sure', 'arrival', 'hello', 'us', 'within', 'hi', \"'m\", 'maximum', 'qx', 'toronto', 'delta', 'american', 'the', 'tomorrow', 'uses', 'beach', 'returning', 'via', 'later', 'those', 'describe', 'diego', 'plan', 'arrive', 'stopping', 'between', 'just', 'get', 'las', 'booking', 'total', 'time', 'lastest', 'actually', 'dollars', 'tacoma', 'dc10', 'right', 'all', 'also', 'for', 'carolina', 'coach', 'capacity', 'arizona', 'earlier', 'far', \"'d\", 'rental', 'going', 'thirtieth', 'february', 'airfare', 'go', 'noon', 'logan', 'should', 'taxi', 'new', 'have', 'names', 'DIGITDIGIT', 'serving', 'indianapolis', 'transportation', 'services', 'way', 'houston', 'week', 'an', 'seventh', 'only', 'costs', 'f28', 'okay', 'or', 'baltimore', 'jersey', 'of', 'texas', 'lufthansa', 'following', 'ea', 'cities', 'display', 'help', 'reservation', 'ground', 'sundays', 'first', 'morning', 'stopovers', 'tickets', 'six', 'fare', 'vegas', 'approximately', 'afternoon', 'yn', 'please', 'into', 'columbus', 'twentieth', 'hp', \"'ll\", 'give', 'kind', 'fourth', 'hours', 'bwi', 'stops', 'georgia', 'starting', 'francisco', 'turboprop', 'classes', 'monday', 'cleveland', 'ord', 'qo', 'ff', 'offers', 'originating', 'june', 'again', 'lives', 'airplanes', 'do', 'many', 'dl', 'cheapest', 'bound', 'choices', 'pittsburgh', 'possible', \"o'clock\", 'around', 'express', 'trip', 'so', 'rentals', 'restriction', 'york', 'dinner', 'saturday', 'too', 'heading', 'dinnertime', 'options', 'want', 'orlando', 'with', 'tampa', 'my', 'anywhere', 'another', 'sa', 'wednesdays', 'direct', 'who', 'more', 'lunch', 'available', 'landing', 'today', 'originate', 'twelfth', 'co', 'repeat', 'tower', 'b', 'as', 'united', 'connections', 'taking', 'utah', 'ohio', 'connection', 'sunday', 'need', 'under', \"'t\", 'yes', 'kinds', 'mean', 'connecting', 'difference', 'evening', 'economy', 'stand', 'number', 'y', 'next', 'landings', 'downtown', 'april', 'airlines', 'flies', 'type', 'near', 'close', 'long', 'using', 'same', 'be', 'minnesota', 'that', 'DIGITDIGITDIGITDIGIT', 'second', 'by', 'located', 'both', 'september', 'sfo', 'h', 'on', 'lake', 'explain', 'sixteenth', 'to', 'fares', 'schedule', 'continental', 'out', 'train', 'wish', 'seattle', 'am', 'ap57', 'worth', 'atlanta', 'midwest', 'it', 'let', 'petersburg', 'stapleton', 'meal', 'limo', 'still', 'salt', '72s', 'july', 'rate', 'county', 'days'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each key of words_dict is a word, each value its index\n",
    "words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'flights',\n",
       " 'leave',\n",
       " 'atlanta',\n",
       " 'at',\n",
       " 'about',\n",
       " 'DIGIT',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'and',\n",
       " 'arrive',\n",
       " 'in',\n",
       " 'san',\n",
       " 'francisco']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we can map the numeric values v in a sentence with the k,v in the dict\n",
    "# train_x contains the list of training sentences\n",
    "# this is the first sentence\n",
    "[k for val in train_x[0] for k,v in words.items() if v==val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco',\n",
       " 'what is the abbreviation for canadian airlines international',\n",
       " \"i 'd like to know the earliest flight from boston to atlanta\",\n",
       " 'show me the us air flights from atlanta to boston',\n",
       " 'show me the cheapest round trips from dallas to baltimore',\n",
       " \"i 'd like to see all flights from denver to philadelphia\",\n",
       " 'explain fare code qx',\n",
       " \"i 'd like a united airlines flight on wednesday from san francisco to boston\",\n",
       " 'what is the price of american airlines flight DIGITDIGIT from new york to los angeles',\n",
       " 'what does the meal code s stand for',\n",
       " 'what are all flights to denver from philadelphia on sunday',\n",
       " 'what times does the late afternoon flight leave from washington for denver',\n",
       " 'what flights are available monday from san francisco to pittsburgh',\n",
       " 'what airlines have business class',\n",
       " 'flights from atlanta to washington dc',\n",
       " 'from new york to toronto on thursday morning',\n",
       " 'show me all the direct flights from atlanta to baltimore',\n",
       " 'list the flights from new york to miami on a tuesday which are nonstop and cost less than DIGITDIGITDIGIT dollars',\n",
       " 'show me the first flight that arrives in toronto from cincinnati',\n",
       " 'what planes are used by twa',\n",
       " 'please give me the prices for all flights from philadelphia to denver airport next sunday',\n",
       " 'show me all flights from pittsburgh to oakland that arrive after DIGITDIGIT am',\n",
       " 'what is the least expensive flight today from atlanta to san francisco',\n",
       " 'i want a flight from philadelphia to dallas with a stop in atlanta',\n",
       " 'show me the flights from baltimore to philadelphia',\n",
       " 'what airlines fly from st. petersburg to milwaukee and from milwaukee to tacoma',\n",
       " 'please give me the flights from san francisco to washington dc',\n",
       " 'i need a flight delta airlines kansas city to salt lake',\n",
       " 'show me flights going from boston to denver arriving on wednesday morning',\n",
       " 'show me flights leaving from denver colorado to pittsburgh pennsylvania on wednesdays after DIGIT pm']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the first few sentences\n",
    "sents = []\n",
    "for i in range(30):\n",
    "    sents.append(' '.join([k for val in train_x[i] for k,v in words.items() if v==val]))\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['I-meal_code', 'B-connect', 'B-depart_date.date_relative', 'B-state_code', 'B-fare_basis_code', 'I-arrive_time.time_relative', 'B-flight_time', 'I-arrive_time.start_time', 'I-depart_time.time', 'B-toloc.airport_name', 'I-economy', 'B-city_name', 'B-toloc.state_name', 'I-cost_relative', 'I-flight_number', 'B-arrive_time.start_time', 'B-depart_time.end_time', 'I-toloc.state_name', 'B-meal', 'B-arrive_time.time', 'B-time_relative', 'B-toloc.state_code', 'I-transport_type', 'B-fromloc.city_name', 'B-depart_time.start_time', 'B-meal_description', 'I-toloc.airport_name', 'I-return_date.day_number', 'B-depart_date.month_name', 'B-arrive_time.period_of_day', 'B-fare_amount', 'B-fromloc.state_name', 'B-return_date.day_name', 'B-stoploc.airport_name', 'B-fromloc.airport_name', 'I-class_type', 'B-flight_number', 'B-depart_date.day_name', 'I-depart_time.end_time', 'B-transport_type', 'I-arrive_time.end_time', 'I-flight_time', 'B-depart_date.year', 'B-fromloc.airport_code', 'B-flight_mod', 'O', 'I-toloc.city_name', 'B-month_name', 'I-fare_amount', 'B-stoploc.airport_code', 'I-fromloc.airport_name', 'B-arrive_date.date_relative', 'I-restriction_code', 'I-return_date.date_relative', 'B-arrive_time.time_relative', 'B-airline_code', 'I-fare_basis_code', 'B-fromloc.state_code', 'B-return_date.today_relative', 'B-return_date.month_name', 'B-airport_code', 'B-arrive_date.day_name', 'B-restriction_code', 'B-depart_time.period_mod', 'B-stoploc.state_code', 'B-state_name', 'I-flight_stop', 'I-fromloc.city_name', 'B-depart_time.time_relative', 'B-stoploc.city_name', 'I-meal_description', 'B-today_relative', 'I-state_name', 'B-mod', 'B-meal_code', 'B-days_code', 'B-compartment', 'B-arrive_time.end_time', 'I-time', 'B-return_time.period_mod', 'B-booking_class', 'B-cost_relative', 'B-time', 'I-depart_date.day_number', 'B-depart_time.period_of_day', 'B-aircraft_code', 'B-round_trip', 'I-fromloc.state_name', 'I-airline_name', 'B-toloc.city_name', 'B-period_of_day', 'I-depart_time.period_of_day', 'B-flight_stop', 'I-flight_mod', 'I-arrive_date.day_number', 'B-airline_name', 'I-arrive_time.period_of_day', 'B-return_date.day_number', 'B-arrive_time.period_mod', 'B-day_number', 'B-flight', 'I-today_relative', 'I-airport_name', 'B-economy', 'I-return_date.today_relative', 'B-day_name', 'B-return_date.date_relative', 'B-class_type', 'B-return_time.period_of_day', 'B-toloc.country_name', 'B-toloc.airport_code', 'B-arrive_date.day_number', 'B-arrive_date.today_relative', 'I-round_trip', 'B-depart_date.day_number', 'B-airport_name', 'I-depart_date.today_relative', 'I-stoploc.city_name', 'B-flight_days', 'I-city_name', 'I-depart_time.start_time', 'B-arrive_date.month_name', 'I-arrive_time.time', 'B-depart_date.today_relative', 'B-or', 'I-depart_time.time_relative', 'B-depart_time.time'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels dict contains IOB (inside-out-beginning) labelled entities\n",
    "labels.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 127 classes of labels (including the 'O' - tokens that do not fall into any entity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "# number of labels\n",
    "print(len(labels.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dicts 'words' and 'labels' are key:value pairs of index:word/label, let's reverse the dicts so that we don't have to do a reverse lookup everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting words_to_id to id_to_words\n",
    "# and labels_to_id to id_to_labels\n",
    "id_to_words = {words[k]:k for k in words}\n",
    "id_to_labels = {labels[k]:k for k in labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the words and corresponding labels simply by looking up the value of a numeric index of each word, for e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('show', 'O'), ('me', 'O'), ('all', 'O'), ('flights', 'O'), ('between', 'O'), ('boston', 'B-fromloc.city_name'), ('and', 'O'), ('washington', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('philadelphia', 'B-fromloc.city_name'), ('to', 'O'), ('boston', 'B-toloc.city_name'), ('monday', 'B-depart_date.day_name')]\n",
      "\n",
      "\n",
      "[('find', 'O'), ('me', 'O'), ('a', 'O'), ('flight', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('san', 'B-toloc.city_name'), ('francisco', 'I-toloc.city_name'), ('with', 'O'), ('a', 'O'), ('layover', 'O'), ('in', 'O'), ('denver', 'B-stoploc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('are', 'O'), ('the', 'O'), ('flights', 'O'), ('from', 'O'), ('atlanta', 'B-fromloc.city_name'), ('to', 'O'), ('baltimore', 'B-toloc.city_name'), ('which', 'O'), ('arrive', 'O'), ('in', 'O'), ('baltimore', 'B-toloc.city_name'), ('at', 'O'), ('DIGIT', 'B-arrive_time.time'), (\"o'clock\", 'I-arrive_time.time'), ('pm', 'I-arrive_time.time')]\n",
      "\n",
      "\n",
      "[('sure', 'O'), ('i', 'O'), (\"'d\", 'O'), ('like', 'O'), ('to', 'O'), ('<UNK>', 'O'), ('what', 'O'), ('aircraft', 'O'), ('are', 'O'), ('use', 'O'), ('on', 'O'), ('july', 'B-depart_date.month_name'), ('seventh', 'B-depart_date.day_number'), ('leaving', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('and', 'O'), ('arriving', 'O'), ('in', 'O'), ('atlanta', 'B-toloc.city_name'), ('on', 'O'), ('july', 'B-arrive_date.month_name'), ('seventh', 'B-arrive_date.day_number')]\n",
      "\n",
      "\n",
      "[('what', 'O'), (\"'s\", 'O'), ('the', 'O'), ('earliest', 'B-flight_mod'), ('flight', 'O'), ('from', 'O'), ('phoenix', 'B-fromloc.city_name'), ('to', 'O'), ('salt', 'B-toloc.city_name'), ('lake', 'I-toloc.city_name'), ('city', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('cheapest', 'B-cost_relative'), ('airfare', 'O'), ('from', 'O'), ('tacoma', 'B-fromloc.city_name'), ('to', 'O'), ('orlando', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('a', 'O'), ('flight', 'O'), ('from', 'O'), ('philadelphia', 'B-fromloc.city_name'), ('to', 'O'), ('dallas', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), (\"'d\", 'O'), ('like', 'O'), ('to', 'O'), ('fly', 'O'), ('early', 'B-depart_time.period_mod'), ('tomorrow', 'B-depart_date.today_relative'), ('from', 'O'), ('columbus', 'B-fromloc.city_name'), ('to', 'O'), ('minneapolis', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('list', 'O'), ('all', 'O'), ('round', 'B-round_trip'), ('trip', 'I-round_trip'), ('flights', 'O'), ('from', 'O'), ('orlando', 'B-fromloc.city_name'), ('to', 'O'), ('kansas', 'B-toloc.city_name'), ('city', 'I-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('flights', 'O'), ('are', 'O'), ('there', 'O'), ('from', 'O'), ('milwaukee', 'B-fromloc.city_name'), ('to', 'O'), ('phoenix', 'B-toloc.city_name'), ('on', 'O'), ('saturday', 'B-depart_date.day_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('all', 'O'), ('flights', 'O'), ('from', 'O'), ('pittsburgh', 'B-fromloc.city_name'), ('to', 'O'), ('baltimore', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('would', 'O'), ('like', 'O'), ('to', 'O'), ('fly', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('baltimore', 'B-toloc.city_name'), ('please', 'O'), ('tell', 'O'), ('me', 'O'), ('what', 'O'), ('are', 'O'), ('the', 'O'), ('times', 'B-flight_time'), ('of', 'O'), ('the', 'O'), ('flights', 'O')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('is', 'O'), ('the', 'O'), ('cost', 'O'), ('for', 'O'), ('a', 'O'), ('one', 'B-round_trip'), ('way', 'I-round_trip'), ('trip', 'O'), ('from', 'O'), ('pittsburgh', 'B-fromloc.city_name'), ('to', 'O'), ('atlanta', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('show', 'O'), ('me', 'O'), ('saturday', 'B-depart_date.day_name'), ('and', 'O'), ('sunday', 'B-depart_date.day_name'), (\"'s\", 'O'), ('flights', 'O'), ('from', 'O'), ('milwaukee', 'B-fromloc.city_name'), ('to', 'O'), ('phoenix', 'B-toloc.city_name'), ('on', 'O'), ('american', 'B-airline_name'), ('airlines', 'I-airline_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('airlines', 'O'), ('fly', 'O'), ('between', 'O'), ('boston', 'B-fromloc.city_name'), ('and', 'O'), ('atlanta', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('list', 'O'), ('types', 'O'), ('of', 'O'), ('planes', 'O'), ('that', 'O'), ('fly', 'O'), ('between', 'O'), ('pittsburgh', 'B-fromloc.city_name'), ('and', 'O'), ('baltimore', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('is', 'O'), ('the', 'O'), ('latest', 'B-flight_mod'), ('flight', 'O'), ('from', 'O'), ('philadelphia', 'B-fromloc.city_name'), ('to', 'O'), ('boston', 'B-toloc.city_name')]\n",
      "\n",
      "\n",
      "[('i', 'O'), ('need', 'O'), ('to', 'O'), ('fly', 'O'), ('from', 'O'), ('boston', 'B-fromloc.city_name'), ('to', 'O'), ('baltimore', 'B-toloc.city_name'), ('please', 'O'), ('give', 'O'), ('me', 'O'), ('the', 'O'), ('times', 'B-flight_time'), ('of', 'I-flight_time'), ('your', 'I-flight_time'), ('flights', 'I-flight_time'), ('in', 'O'), ('the', 'O'), ('morning', 'B-depart_time.period_of_day'), ('before', 'B-depart_time.time_relative'), ('DIGIT', 'B-depart_time.time'), (\"o'clock\", 'I-depart_time.time')]\n",
      "\n",
      "\n",
      "[('what', 'O'), ('does', 'O'), ('mco', 'B-airport_code'), ('stand', 'O'), ('for', 'O')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing a few randomly chosen sentences and the corresponding labels (tagged entities)\n",
    "for i in random.sample(range(len(train_x)), 20):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[i]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[i]))\n",
    "    print(list(zip(w, l)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function which takes in an index and returns the corresponding query with its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_query(index):\n",
    "    w = list(map(lambda x: id_to_words[x], train_x[index]))\n",
    "    l = list(map(lambda x: id_to_labels[x], train_label[index]))\n",
    "    s = list(zip(w, l))\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('on', 'O'),\n",
       " ('<UNK>', 'B-airline_name'),\n",
       " ('air', 'I-airline_name'),\n",
       " ('how', 'O'),\n",
       " ('many', 'O'),\n",
       " ('flights', 'O'),\n",
       " ('leaving', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('july', 'B-depart_date.month_name'),\n",
       " ('twenty', 'B-depart_date.day_number'),\n",
       " ('seventh', 'I-depart_date.day_number'),\n",
       " ('to', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('nonstop', 'B-flight_stop')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3925)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some queries specify stopover cities, such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'O'),\n",
       " ('there', 'O'),\n",
       " ('a', 'O'),\n",
       " ('flight', 'O'),\n",
       " ('between', 'O'),\n",
       " ('oakland', 'B-fromloc.city_name'),\n",
       " ('and', 'O'),\n",
       " ('boston', 'B-toloc.city_name'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('stopover', 'O'),\n",
       " ('in', 'O'),\n",
       " ('dallas', 'B-stoploc.city_name'),\n",
       " ('fort', 'I-stoploc.city_name'),\n",
       " ('worth', 'I-stoploc.city_name'),\n",
       " ('on', 'O'),\n",
       " ('twa', 'B-airline_code')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_query(3443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this dataset, queries are far more complex (in terms of number of labels, variety in the sentence structures etc.) and thus we cannot  write simple hand-written rules to extract chunks such as to_from_city, types_of_meals etc. \n",
    "\n",
    "Thus, we need to train probabilistic models such as CRFs, HMMs etc. to tag each word with its corresponding entity label.\n",
    "\n",
    "We'll use the training and validation sets ```train_x``` and ```valid_x``` as to tune the model, and finaly use test set to measure the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for NER\n",
    "\n",
    "Let's experiment with a few different models for labelling words with named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging sentences\n",
    "def pos_tag(sent_list):\n",
    "    pos_tags = []\n",
    "    \n",
    "    for sent in sent_list:\n",
    "        tagged_words = nltk.pos_tag([id_to_words[val] for val in sent])\n",
    "        pos_tags.append(tagged_words)\n",
    "\n",
    "    return pos_tags\n",
    "\n",
    "train_pos = pos_tag(train_x)\n",
    "valid_pos = pos_tag(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('show', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('list', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('flights', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('san', 'JJ'),\n",
       " ('francisco', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('boston', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('august', 'NN'),\n",
       " ('thirtieth', 'NN')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at tags of some randomly chosen queries\n",
    "# notice that most cities after 'TO' are tagged as VB\n",
    "i = random.randrange(len(train_pos))\n",
    "train_pos[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating list of tuples for each query of the form:\n",
    "```[('New', 'NNP', u'B-GPE'), ('York', 'NNP', u'I-GPE'), ('is', 'VBZ', u'O'), ('my', 'PRP$', u'O'), ('favorite', 'JJ', u'O'), ('city', 'NN', u'O')]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting each word in train sentences to 3-tuples \n",
    "# of the form (word, tag, IOB_tag)\n",
    "train_labels = []\n",
    "for sent in list(zip(train_pos, train_label)):\n",
    "    pos = sent[0]\n",
    "    labels = sent[1]\n",
    "    l = list(zip(pos, labels))\n",
    "    tuple_3 = [(i[0][0], i[0][1], id_to_labels[i[1]]) for i in l]\n",
    "    train_labels.append(tuple_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WP', 'O'),\n",
       " ('flights', 'VBD', 'O'),\n",
       " ('does', 'VBZ', 'O'),\n",
       " ('delta', 'NNS', 'B-airline_name'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('between', 'IN', 'O'),\n",
       " ('dallas', 'NNS', 'B-fromloc.city_name'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('denver', 'NN', 'B-toloc.city_name')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some sample training sentences\n",
    "train_labels[random.randrange(len(train_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same for validation data\n",
    "\n",
    "valid_labels = []\n",
    "for sent in list(zip(valid_pos, val_label)):\n",
    "    pos = sent[0]\n",
    "    labels = sent[1]\n",
    "    l = list(zip(pos, labels))\n",
    "    tuple_3 = [(i[0][0], i[0][1], id_to_labels[i[1]]) for i in l]\n",
    "    valid_labels.append(tuple_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to tree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  i/JJ\n",
      "  'd/MD\n",
      "  like/VB\n",
      "  to/TO\n",
      "  know/VB\n",
      "  the/DT\n",
      "  (flight_mod earliest/JJS)\n",
      "  flight/NN\n",
      "  from/IN\n",
      "  (fromloc.city_name boston/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name atlanta/VB))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2000\n",
    "from nltk import conlltags2tree, tree2conlltags\n",
    "\n",
    "# converting a sample sentence to a tree\n",
    "tree = conlltags2tree(train_labels[2])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert all training sentences to trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training and validation data to tree format\n",
    "train_trees = [conlltags2tree(sent) for sent in train_labels]\n",
    "valid_trees = [conlltags2tree(sent) for sent in valid_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  flights/NNS\n",
      "  from/IN\n",
      "  (fromloc.city_name chicago/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name denver/VB)\n",
      "  on/IN\n",
      "  (airline_name continental/NN)\n",
      "  on/IN\n",
      "  (depart_date.day_name saturday/JJ)\n",
      "  (depart_time.period_of_day morning/NN))\n"
     ]
    }
   ],
   "source": [
    "# print some sample training trees\n",
    "print(train_trees[random.randrange(len(train_trees))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try building some parsers. \n",
    "\n",
    "### Regex Based Parsers\n",
    "\n",
    "Let's start with a dummy parser - one which tags every token as an 'O'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  63.6%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# a dummy chunk parser - tags every word as 'O'\n",
    "cp = nltk.RegexpParser(r'')\n",
    "print(cp.evaluate(valid_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  what/WP\n",
      "  aircraft/NN\n",
      "  is/VBZ\n",
      "  used/VBN\n",
      "  on/IN\n",
      "  (airline_name delta/JJ)\n",
      "  flight/NN\n",
      "  (flight_number DIGITDIGITDIGITDIGIT/NNP)\n",
      "  from/IN\n",
      "  (fromloc.city_name kansas/NNP city/NN)\n",
      "  to/TO\n",
      "  (toloc.city_name salt/VB lake/JJ city/NN))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(valid_trees[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tell us that about 63% of the tokens are tagged as 'O', i.e. they are not a named entity of any type. The precision, recall etc. are zero because we did not find any chunks at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Gazetteer to Lookup Cities\n",
    "\n",
    "URL: https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State short</th>\n",
       "      <th>State full</th>\n",
       "      <th>County</th>\n",
       "      <th>City alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Internal Revenue Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>SUFFOLK</td>\n",
       "      <td>Holtsville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>URB San Joaquin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Jard De Adjuntas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>ADJUNTAS</td>\n",
       "      <td>Colinas Del Gigante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State short   State full    County                City alias\n",
       "0  Holtsville          NY     New York   SUFFOLK  Internal Revenue Service\n",
       "1  Holtsville          NY     New York   SUFFOLK                Holtsville\n",
       "2    Adjuntas          PR  Puerto Rico  ADJUNTAS           URB San Joaquin\n",
       "3    Adjuntas          PR  Puerto Rico  ADJUNTAS          Jard De Adjuntas\n",
       "4    Adjuntas          PR  Puerto Rico  ADJUNTAS       Colinas Del Gigante"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading a file containing list of US cities, states and counties\n",
    "us_cities = pd.read_csv(\"us_cities_states_counties.csv\", sep=\"|\")\n",
    "us_cities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing cities, states and counties as sets\n",
    "cities = set(us_cities['City'].str.lower())\n",
    "states = set(us_cities['State full'].str.lower())\n",
    "counties = set(us_cities['County'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18854\n",
      "62\n",
      "1932\n"
     ]
    }
   ],
   "source": [
    "print(len(cities))\n",
    "print(len(states))\n",
    "print(len(counties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to look up a given word in cities, states, county\n",
    "def gazetteer_lookup(word):\n",
    "    return (word in cities, word in states, word in counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, True)\n",
      "(False, True, True)\n",
      "(True, False, True)\n"
     ]
    }
   ],
   "source": [
    "# sample lookups\n",
    "print(gazetteer_lookup('washington'))\n",
    "\n",
    "# utah is not a city, but a state and county\n",
    "print(gazetteer_lookup('utah'))\n",
    "\n",
    "# chicago is a city\n",
    "print(gazetteer_lookup('denver'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "We can now lookup each word in the gazetteer and assign a class (entity label) accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
